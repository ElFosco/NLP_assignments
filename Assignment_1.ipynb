{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ElFosco/NLP_assignments/blob/main/Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WeCeITXoxLf"
      },
      "source": [
        "# Assignment 1\n",
        "\n",
        "**Due to**: 23/12/2021 (dd/mm/yyyy)\n",
        "\n",
        "**Credits**: Andrea Galassi, Federico Ruggeri, Paolo Torroni\n",
        "\n",
        "**Summary**: Part-of Speech (POS) tagging as Sequence Labelling using Recurrent Neural Architectures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4_wqPdlBcKS"
      },
      "source": [
        "# Intro\n",
        "\n",
        "In this assignment  we will ask you to perform POS tagging using neural architectures\n",
        "\n",
        "You are asked to follow these steps:\n",
        "*   Download the corpora and split it in training and test sets, structuring a dataframe.\n",
        "*   Embed the words using GloVe embeddings\n",
        "*   Create a baseline model, using a simple neural architecture\n",
        "*   Experiment doing small modifications to the baseline model, choose hyperparameters using the validation set\n",
        "*   Evaluate your two best model\n",
        "*   Analyze the errors of your model\n",
        "\n",
        "\n",
        "**Task**: given a corpus of documents, predict the POS tag for each word\n",
        "\n",
        "**Corpus**:\n",
        "Ignore the numeric value in the third column, use only the words/symbols and its label. \n",
        "The corpus is available at:\n",
        "https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip\n",
        "\n",
        "**Splits**: documents 1-100 are the train set, 101-150 validation set, 151-199 test set.\n",
        "\n",
        "\n",
        "**Features**: you MUST use GloVe embeddings as the only input features to the model.\n",
        "\n",
        "**Splitting**: you can decide to split documents into sentences or not, the choice is yours.\n",
        "\n",
        "**I/O structure**: The input data will have three dimensions: 1-documents/sentences, 2-token, 3-features; for the output there are 2 possibilities: if you use one-hot encoding it will be 1-documents/sentences, 2-token labels, 3-classes, if you use a single integer that indicates the number of the class it will be 1-documents/sentences, 2-token labels.\n",
        "\n",
        "**Baseline**: two layers architecture: a Bidirectional LSTM layer and a Dense/Fully-Connected layer on top; the choice of hyper-parameters is yours.\n",
        "\n",
        "**Architectures**: experiment using a GRU instead of the LSTM, adding an additional LSTM layer, and adding an additional dense layer; do not mix these variantions.\n",
        "\n",
        "\n",
        "**Training and Experiments**: all the experiments must involve only the training and validation sets.\n",
        "\n",
        "**Evaluation**: in the end, only the two best models of your choice (according to the validation set) must be evaluated on the test set. The main metric must be F1-Macro computed between the various part of speech. DO NOT CONSIDER THE PUNCTUATION CLASSES.\n",
        "\n",
        "**Metrics**: the metric you must use to evaluate your final model is the F1-macro, WITHOUT considering punctuation/symbols classes; during the training process you can use accuracy because you can't use the F1 metric unless you use a single (gigantic) batch because there is no way to aggregate \"partial\" F1 scores computed on mini-batches.\n",
        "\n",
        "**Discussion and Error Analysis** : verify and discuss if the results on the test sets are coherent with those on the validation set; analyze the errors done by your model, try to understand which may be the causes and think about how to improve it.\n",
        "\n",
        "**Report**: you are asked to deliver the code of your experiments and a small pdf report of about 2 pages; the pdf must begin with the names of the people of your team and a small abstract (4-5 lines) that sums up your findings.\n",
        "\n",
        "# Out Of Vocabulary (OOV) terms\n",
        "\n",
        "How to handle words that are not in GloVe vocabulary?\n",
        "You can handle them as you want (random embedding, placeholder, whatever!), but they must be STATIC embeddings (you cannot train them).\n",
        "\n",
        "But there is a very important caveat! As usual, the element of the test set must not influence the elements of the other splits!\n",
        "\n",
        "So, when you compute new embeddings for train+validation, you must forget about test documents.\n",
        "The motivation is to emulate a real-world scenario, where you select and train a model in the first stage, without knowing nothing about the testing environment.\n",
        "\n",
        "For implementation convenience, you CAN use a single vocabulary file/matrix/whatever. The principle of the previous point is that the embeddings inside that file/matrix must be generated independently for train and test splits.\n",
        "\n",
        "Basically in a real-world scenario, this is what would happen:\n",
        "1. Starting vocabulary V1 (in this assignment, GloVe vocabulary)\n",
        "2. Compute embeddings for terms out of vocabulary V1 (OOV1) of the training split \n",
        "3. Add embeddings to the vocabulary, so to obtain vocabulary V2=V1+OOV1\n",
        "4. Training of the model(s)\n",
        "5. Compute embeddings for terms OOV2 of the validation split \n",
        "6. Add embeddings to the vocabulary, so to obtain vocabulary V3=V1+OOV1+OOV2\n",
        "7. Validation of the model(s)\n",
        "8. Compute embeddings for terms OOV3 of the test split \n",
        "9. Add embeddings to the vocabulary, so to obtain vocabulary V4=V1+OOV1+OOV2+OOV3\n",
        "10. Testing of the final model\n",
        "\n",
        "In this case, where we already have all the documents, we can simplify the process a bit, but the procedure must remain rigorous.\n",
        "\n",
        "1. Starting vocabulary V1 (in this assignment, GloVe vocabulary)\n",
        "2. Compute embeddings for terms out of vocabulary V1 (OOV1) of the training split \n",
        "3. Add embeddings to the vocabulary, so to obtain vocabulary V2=V1+OOV1\n",
        "4. Compute embeddings for terms OOV2 of the validation split \n",
        "5. Add embeddings to the vocabulary, so to obtain vocabulary V3=V1+OOV1+OOV2\n",
        "6. Compute embeddings for terms OOV3 of the test split \n",
        "7. Add embeddings to the vocabulary, so to obtain vocabulary V4=V1+OOV1+OOV2\n",
        "8. Training of the model(s)\n",
        "9. Validation of the model(s)\n",
        "10. Testing of the final model\n",
        "\n",
        "Step 2 and step 6 must be completely independent of each other, for what concerns the method and the documents. But they can rely on the previous vocabulary (V1 for step 2 and V3 for step 6)\n",
        "THEREFORE if a word is present both in the training set and the test split and not in the starting vocabulary, its embedding is computed in step 2) and it is not considered OOV anymore in step 6).\n",
        "\n",
        "# Report\n",
        "The report must not be just a copy and paste of graphs and tables!\n",
        "\n",
        "The report must not be longer than 2 pages and must contain:\n",
        "* The names of the member of your team\n",
        "* A short abstract (4-5 lines) that sum ups everything\n",
        "* A general description of the task you have addressed and how you have addressed it\n",
        "* A short description of the models you have used\n",
        "* Some tables that sum up your findings in validation and test and a discussion of those results\n",
        "* The most relevant findings of your error analysis\n",
        "\n",
        "# Evaluation Criterion\n",
        "\n",
        "The goal of this assignment is not to prove you can find best model ever, but to face a common task, structure it correctly, and follow a correct and rigorous experimental procedure.\n",
        "In other words, we don't care if you final models are awful as long as you have followed the correct procedure and wrote a decent report.\n",
        "\n",
        "The score of the assignment will be computed roughly as follows\n",
        "* 1 point for the general setting of the problem\n",
        "* 1 point for the handling of OOV terms\n",
        "* 1 point for the models\n",
        "* 1 point for train-validation-test procedure\n",
        "* 2 point for the discussion of the results, error analysis, and report\n",
        "\n",
        "This distribution of scores is tentative and we may decide to alter it at any moment.\n",
        "We also reserve the right to assign a small bonus (0.5 points) to any assignment that is particularly worthy. Similarly, in case of grave errors, we may decide to assign an equivalent malus (-0.5 points).\n",
        "\n",
        "# Contacts\n",
        "\n",
        "In case of any doubt, question, issue, or help we highly recommend you to check the [course useful material](https://virtuale.unibo.it/pluginfile.php/1036039/mod_resource/content/2/NLP_Course_Useful_Material.pdf) for additional information, and to use the Virtuale forums to discuss with other students.\n",
        "\n",
        "You can always contact us at the following email addresses. To increase the probability of a prompt response, we reccomend you to write to both the teaching assistants.\n",
        "\n",
        "Teaching Assistants:\n",
        "\n",
        "* Andrea Galassi -> a.galassi@unibo.it\n",
        "* Federico Ruggeri -> federico.ruggeri6@unibo.it\n",
        "\n",
        "Professor:\n",
        "\n",
        "* Paolo Torroni -> p.torroni@unibo.it\n",
        "\n",
        "\n",
        "# FAQ\n",
        "* You can use a non-trainable Embedding layer to load the glove embeddings\n",
        "* You can use any library of your choice to implement the networks. Two options are tensorflow/keras or pythorch. Both these libraries have all the classes you need to implement these simple architectures and there are plenty of tutorials around, where you can learn how to use them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCkKqTG1R2A3"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCFUaNkDHxvU"
      },
      "source": [
        "import os, shutil  # file management\n",
        "import sys \n",
        "import pandas as pd  # dataframe management\n",
        "import numpy as np  # data manipulation\n",
        "from tqdm import tqdm  # useful during debugging (progress bars)\n",
        "from typing import List, Callable, Dict  # typing\n",
        "import re  # regex\n",
        "import urllib.request  # download files\n",
        "import zipfile  # unzip files\n",
        "import gensim  # embeddings\n",
        "import gensim.downloader as gloader  # embeddings\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uk40AfIRyk9"
      },
      "source": [
        "# Dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZEog8bfHZkn"
      },
      "source": [
        "Download the corpora and split it in training and test sets, structuring a dataframe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00vKWJXWIKdH"
      },
      "source": [
        "## Download & Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjYnrT-jGto5",
        "outputId": "0c7a9d5d-a3ff-4f12-ac07-c52994cba1c1"
      },
      "source": [
        "dataset_folder = os.path.join(os.getcwd(), \"Datasets\", \"Original\")\n",
        "\n",
        "if not os.path.exists(dataset_folder):\n",
        "    os.makedirs(dataset_folder)\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip'\n",
        "\n",
        "dataset_path = os.path.join(dataset_folder, \"dependency_treebank.zip\")\n",
        "\n",
        "if not os.path.exists(dataset_path):\n",
        "    urllib.request.urlretrieve(url, dataset_path)\n",
        "    print(\"Successful download\")\n",
        "\n",
        "zip = zipfile.ZipFile(dataset_path)\n",
        "zip.extractall(dataset_folder)\n",
        "zip.close()\n",
        "print(\"Successful extraction\")"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successful extraction\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-frhRxTJIM6p"
      },
      "source": [
        "## Creation Dataframe and splitting (check if pre processing is needed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4p1Q1UogPZM"
      },
      "source": [
        "### [Regex](https://regex101.com/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wnHGfB3gQzs"
      },
      "source": [
        "symbol_remove_alone = \"^[\\.,\\-$'\\\";?!#:`]*$\"  # symbol(s) between ^(start) and $(end)\n",
        "pattern_alone = re.compile(symbol_remove_alone)\n",
        "\n",
        "symbol_number = \"^[\\.,:'/\\-0-9]*(s|th)?$\"  # finds number\n",
        "pattern_number = re.compile(symbol_number)\n",
        "\n",
        "# @ is associated to IN\n",
        "# & and % are used as NN and CC, maybe we should not remove them even if alone?\n",
        "# should we check also other symbols? we should not know what comes in the test set \n",
        "#test = \"^[/&%£\\(\\)\\{\\}\\[\\]\\^|]*$\"\n",
        "#pattern_test = re.compile(test)"
      ],
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCeV9etBhEJv"
      },
      "source": [
        "### Creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNL6xexFIJ5F"
      },
      "source": [
        "folder = \"/content/Datasets/Original/dependency_treebank\"\n",
        "folder_pkl = \"/content/Datasets/Original\"\n",
        "dataset_name = \"dependency_treebank\"\n",
        "\n",
        "dataframe_rows_train = []\n",
        "dataframe_rows_val = []\n",
        "dataframe_rows_test = []\n",
        "\n",
        "bad_tokens = ('-LRB-','-RRB-','US$','C$','Wa')\n",
        "i=0\n",
        "\n",
        "sentence=0\n",
        "sentence_max_length=0\n",
        "sentence_length=0\n",
        "\n",
        "files = os.listdir(folder)\n",
        "files.sort()\n",
        "for filename in files:\n",
        "  i+=1\n",
        "  file_path = os.path.join(folder, filename)\n",
        "  try:\n",
        "    if os.path.isfile(file_path):\n",
        "      with open(file_path, mode='r', encoding='utf-8') as text_file:\n",
        "        lines = text_file.readlines()\n",
        "        for line in lines:\n",
        "          if line != '\\n':\n",
        "            word = str(line.split('\\t')[0])\n",
        "            pos = line.split('\\t')[1]\n",
        "\n",
        "            if pattern_alone.match(word) is None and word not in bad_tokens:  # Using regex, if None no match has been found\n",
        "              word = word.replace(\"\\/\", \"/\")  # Avoids \\/ substring in fractions or pair of names.\n",
        "              if pattern_number.match(word):  # Associating a unique token to each number\n",
        "                word = \"NUMBER_TOKEN\"\n",
        "              word = re.sub(\"[0-9]+\", \"NUMBER_TOKEN\", word)  # Replaces number with unique token in each string\n",
        "                \n",
        "              dataframe_row = {\n",
        "                  \"word\": word,\n",
        "                  \"pos\": pos,\n",
        "                  \"sentence\": sentence\n",
        "                  }\n",
        "              sentence_length+=1\n",
        "              if i>=1 and i<=100:\n",
        "                dataframe_rows_train.append(dataframe_row)\n",
        "              elif i>=101 and i<=150:\n",
        "                dataframe_rows_val.append(dataframe_row)\n",
        "              elif i>=151 and i<=199:\n",
        "                dataframe_rows_test.append(dataframe_row)\n",
        "          else:\n",
        "            sentence+=1\n",
        "            if sentence_max_length< sentence_length :\n",
        "              sentence_max_length = sentence_length\n",
        "              \n",
        "            sentence_length=0\n",
        "  except Exception as e:\n",
        "    print('Failed to process %s. Reason: %s' % (file_path, e))\n",
        "    sys.exit(0)\n",
        "\n",
        "dataframe_train = pd.DataFrame(dataframe_rows_train)\n",
        "dataframe_val = pd.DataFrame(dataframe_rows_val)\n",
        "dataframe_test = pd.DataFrame(dataframe_rows_test)\n",
        "\n",
        "dataframe_train = dataframe_train[[\"word\",\"pos\",\"sentence\"]]\n",
        "dataframe_test = dataframe_test[[\"word\",\"pos\",\"sentence\"]]\n",
        "dataframe_val = dataframe_val[[\"word\",\"pos\",\"sentence\"]]\n",
        "\n",
        "dataframe_train_path = os.path.join(folder_pkl, dataset_name + \"_train.pkl\")\n",
        "dataframe_val_path = os.path.join(folder_pkl, dataset_name + \"_val.pkl\")\n",
        "dataframe_test_path = os.path.join(folder_pkl, dataset_name + \"_test.pkl\")\n",
        "dataframe_train.to_pickle(dataframe_train_path)\n",
        "dataframe_test.to_pickle(dataframe_val_path)\n",
        "dataframe_val.to_pickle(dataframe_test_path)\n",
        "\n",
        "dataframe = pd.concat([dataframe_train,dataframe_val,dataframe_test])\n"
      ],
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8NEmJp1Ui6z"
      },
      "source": [
        "## Create GloVe embeddings (keep attention to the size, maybe we have to change it)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SgHagnSUlxq"
      },
      "source": [
        "def load_embedding_model(model_type: str,\n",
        "                         embedding_dimension: int = 50) -> gensim.models.keyedvectors.KeyedVectors:\n",
        "    \"\"\"\n",
        "    Loads a pre-trained word embedding model via gensim library.\n",
        "\n",
        "    :param model_type: name of the word embedding model to load.\n",
        "    :param embedding_dimension: size of the embedding space to consider\n",
        "\n",
        "    :return\n",
        "        - pre-trained word embedding model (gensim KeyedVectors object)\n",
        "    \"\"\"\n",
        "\n",
        "    download_path = \"\"\n",
        "\n",
        "    # Find the correct embedding model name\n",
        "    if model_type.strip().lower() == 'word2vec':\n",
        "        download_path = \"word2vec-google-news-300\"\n",
        "\n",
        "    elif model_type.strip().lower() == 'glove':\n",
        "        download_path = \"glove-wiki-gigaword-{}\".format(embedding_dimension)\n",
        "    elif model_type.strip().lower() == 'fasttext':\n",
        "        download_path = \"fasttext-wiki-news-subwords-300\"\n",
        "    else:\n",
        "        raise AttributeError(\"Unsupported embedding model type! Available ones: word2vec, glove, fasttext\")\n",
        "\n",
        "    # Check download\n",
        "    try:\n",
        "        emb_model = gloader.load(download_path)\n",
        "    except ValueError as e:\n",
        "        print(\"Invalid embedding model name! Check the embedding dimension:\")\n",
        "        print(\"Word2Vec: 300\")\n",
        "        print(\"Glove: 50, 100, 200, 300\")\n",
        "        raise e\n",
        "\n",
        "    return emb_model"
      ],
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mff7TRr0V8hv"
      },
      "source": [
        "def check_OOV_terms(embedding_model: gensim.models.keyedvectors.KeyedVectors,\n",
        "                    word_listing: List[str]):\n",
        "    \"\"\"\n",
        "    Checks differences between pre-trained embedding model vocabulary\n",
        "    and dataset specific vocabulary in order to highlight out-of-vocabulary terms.\n",
        "\n",
        "    :param embedding_model: pre-trained word embedding model (gensim wrapper)\n",
        "    :param word_listing: dataset specific vocabulary (list)\n",
        "\n",
        "    :return\n",
        "        - list of OOV terms\n",
        "    \"\"\"\n",
        "\n",
        "    embedding_vocabulary = set(embedding_model.vocab.keys())\n",
        "    oov = set(word_listing).difference(embedding_vocabulary)\n",
        "    return list(oov)"
      ],
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ks3PUZeyFuYB"
      },
      "source": [
        "def build_embedding_matrix(embedding_model: gensim.models.keyedvectors.KeyedVectors,\n",
        "                           embedding_dimension: int,\n",
        "                           word_to_idx: Dict[str, int],\n",
        "                           vocab_size: int,\n",
        "                           oov_terms: List[str]) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Builds the embedding matrix of a specific dataset given a pre-trained word embedding model\n",
        "\n",
        "    :param embedding_model: pre-trained word embedding model (gensim wrapper)\n",
        "    :param word_to_idx: vocabulary map (word -> index) (dict)\n",
        "    :param vocab_size: size of the vocabulary\n",
        "    :param oov_terms: list of OOV terms (list)\n",
        "\n",
        "    :return\n",
        "        - embedding matrix that assigns a high dimensional vector to each word in the dataset specific vocabulary (shape |V| x d)\n",
        "    \"\"\"\n",
        "\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dimension), dtype=np.float32)\n",
        "\n",
        "    for word, idx in tqdm(word_to_idx.items()):\n",
        "        try:\n",
        "            embedding_vector = embedding_model[word]\n",
        "        except (KeyError, TypeError):\n",
        "            embedding_vector = np.random.uniform(low=-0.05, high=0.05, size=embedding_dimension)\n",
        "\n",
        "        embedding_matrix[idx] = embedding_vector\n",
        "\n",
        "    return embedding_matrix\n"
      ],
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHclnVYLXWZN"
      },
      "source": [
        "# Modify these variables as you wish!\n",
        "# Glove -> 50, 100, 200, 300\n",
        "# Word2Vec -> 300\n",
        "# Fasttext -> 300\n",
        "\n",
        "class KerasTokenizer(object):\n",
        "    \"\"\"\n",
        "    A simple high-level wrapper for the Keras tokenizer.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, build_embedding_matrix=False, embedding_dimension=None,\n",
        "                 embedding_model_type=None, tokenizer_args=None):\n",
        "        if build_embedding_matrix:\n",
        "            assert embedding_model_type is not None\n",
        "            assert embedding_dimension is not None and type(embedding_dimension) == int\n",
        "\n",
        "        self.build_embedding_matrix = build_embedding_matrix\n",
        "        self.embedding_dimension = embedding_dimension\n",
        "        self.embedding_model_type = embedding_model_type\n",
        "        self.embedding_model = None\n",
        "        self.embedding_matrix = None\n",
        "        self.vocab = None\n",
        "\n",
        "        tokenizer_args = {} if tokenizer_args is None else tokenizer_args\n",
        "        assert isinstance(tokenizer_args, dict) or isinstance(tokenizer_args, collections.OrderedDict)\n",
        "\n",
        "        self.tokenizer_args = tokenizer_args\n",
        "\n",
        "    def build_vocab(self, data, **kwargs):\n",
        "        print('Fitting tokenizer...')\n",
        "        self.tokenizer = tf.keras.preprocessing.text.Tokenizer(**self.tokenizer_args)\n",
        "        self.tokenizer.fit_on_texts(data)\n",
        "        print('Fit completed!')\n",
        "\n",
        "        self.vocab = self.tokenizer.word_index\n",
        "\n",
        "        if self.build_embedding_matrix:\n",
        "            print('Loading embedding model! It may take a while...')\n",
        "            self.embedding_model = load_embedding_model(model_type=self.embedding_model_type,\n",
        "                                                        embedding_dimension=self.embedding_dimension)\n",
        "            \n",
        "            print('Checking OOV terms...')\n",
        "            self.oov_terms = check_OOV_terms(embedding_model=self.embedding_model,\n",
        "                                             word_listing=list(self.vocab.keys()))\n",
        "\n",
        "            print('Building the embedding matrix...')\n",
        "            self.embedding_matrix = build_embedding_matrix(embedding_model=self.embedding_model,\n",
        "                                                           word_to_idx=self.vocab,\n",
        "                                                           vocab_size=len(self.vocab) + 1,          \n",
        "                                                           embedding_dimension=self.embedding_dimension,\n",
        "                                                           oov_terms=self.oov_terms)\n",
        "            print('Done!')\n",
        "\n",
        "\n",
        "    def get_info(self):\n",
        "        return {\n",
        "            'build_embedding_matrix': self.build_embedding_matrix,\n",
        "            'embedding_dimension': self.embedding_dimension,\n",
        "            'embedding_model_type': self.embedding_model_type,\n",
        "            'embedding_matrix': self.embedding_matrix.shape if self.embedding_matrix is not None else self.embedding_matrix,\n",
        "            'embedding_model': self.embedding_model,\n",
        "            'vocab_size': len(self.vocab) + 1,\n",
        "        }\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        return text\n",
        "\n",
        "    def convert_tokens_to_ids(self, tokens):\n",
        "        if type(tokens) == str:\n",
        "            return self.tokenizer.texts_to_sequences([tokens])[0]\n",
        "        else:\n",
        "            return self.tokenizer.texts_to_sequences(tokens)\n",
        "\n",
        "    def convert_ids_to_tokens(self, ids):\n",
        "        return self.tokenizer.sequences_to_texts(ids)"
      ],
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rd7WJ8fOerEt",
        "outputId": "1f806c63-0d11-4b50-97b0-13df9a38be74"
      },
      "source": [
        "tokenizer_args = {\n",
        "    'oov_token': \"OOV_TOKEN\",  # The vocabulary id for unknown terms during text conversion\n",
        "    'lower' : True,  # default\n",
        "    'filters' : '' \n",
        "}\n",
        "tokenizer = KerasTokenizer(tokenizer_args=tokenizer_args,\n",
        "                           build_embedding_matrix=True,\n",
        "                           embedding_dimension=50,\n",
        "                           embedding_model_type=\"glove\")\n",
        "tokenizer.build_vocab(dataframe_train[\"word\"])\n",
        "\n",
        "tokenizer_info = tokenizer.get_info()\n",
        "\n",
        "print('Tokenizer info: ', tokenizer_info)"
      ],
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting tokenizer...\n",
            "Fit completed!\n",
            "Loading embedding model! It may take a while...\n",
            "Checking OOV terms...\n",
            "Building the embedding matrix...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6912/6912 [00:00<00:00, 240280.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done!\n",
            "Tokenizer info:  {'build_embedding_matrix': True, 'embedding_dimension': 50, 'embedding_model_type': 'glove', 'embedding_matrix': (6913, 50), 'embedding_model': <gensim.models.keyedvectors.Word2VecKeyedVectors object at 0x7f206bbf25d0>, 'vocab_size': 6913}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPHTtHKPkNPx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7efe696-316f-46ac-fc40-7dc5832e96ee"
      },
      "source": [
        "a = list(tokenizer.vocab.keys())\n",
        "a.sort()\n",
        "print(a)"
      ],
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['%', '&', \"'d\", \"'ll\", \"'m\", \"'re\", \"'ve\", '-lcb-', '-rcb-', '@', 'OOV_TOKEN', 'a', 'a.', 'a.c.', 'a.d.', 'aba', 'abating', 'abbey', 'abbot', 'abide', 'ability', 'able', 'abortion', 'abortion-related', 'abortionist', 'abortions', 'about', 'above', 'abroad', 'absorbed', 'abuse', 'ac-number_tokenu', 'academic', 'academically', 'acceded', 'accelerated', 'acceleration', 'accept', 'acceptance', 'accepted', 'accepting', 'access', 'accessories', 'accidentally', 'accidents', 'accommodate', 'according', 'account', 'accountants', 'accounting', 'accounts', 'accrued', 'accumulated', 'accurate', 'accurately', 'accused', 'accusing', 'aces', 'acetate', 'achieve', 'achieved', 'achievement', 'achievement-test', 'achieving', 'acknowledge', 'acknowledging', 'acne', 'acquire', 'acquired', 'acquiring', 'acquisition', 'acquisitions', 'acre', 'acres', 'across', 'act', 'acted', 'acting', 'action', 'actions', 'active', 'actively', 'activities', 'activity', 'actor', 'actress', 'acts', 'actual', 'actually', 'ad', 'adams', 'adapted', 'add', 'added', 'adding', 'addition', 'additional', 'additions', 'address', 'addresses', 'addressing', 'adds', 'adequately', 'adjusted', 'adjusting', 'administration', 'administrations', 'administrative', 'administrator', 'administrators', 'admits', 'admitted', 'admitting', 'adolph', 'adopted', 'adopting', 'adrs', 'ads', 'adult', 'adults', 'advance', 'advanced', 'advances', 'advancing', 'advantage', 'advantages', 'advertise', 'advertised', 'advertisements', 'advertisers', 'advertising', 'advertorial', 'advice', 'advised', 'adviser', 'advisory', 'advocate', 'advocates', 'aerospace', 'affair', 'affairs', 'affiliate', 'affiliates', 'afflicted', 'affordable', 'afraid', 'after', 'afternoon', 'afterwards', 'ag', 'again', 'against', 'age', 'agency', 'agents', 'aggravated', 'aggressive', 'aggressively', 'aghast', 'agnew', 'ago', 'agree', 'agreed', 'agreeing', 'agreement', 'agrees', 'agriculture', 'ahead', 'ai', 'aid', 'aide', 'aides', 'aids', 'ailes', 'ailing', 'aim', 'aimed', 'aiming', 'aims', 'air', 'aircraft', 'aired', 'airlines', 'airports', 'aisles', 'akerfeldt', 'akio', 'al', 'ala', 'ala.', 'alan', 'alarmed', 'albany', 'albert', 'albuquerque', 'alerts', 'alexander', 'alienated', 'alive', 'all', 'allegations', 'alleged', 'allegedly', 'alleghany', 'alleging', 'allen', 'alliance', 'allocated', 'allow', 'allowed', 'almost', 'aloha', 'alone', 'along', 'already', 'also', 'altair', 'altar', 'altering', 'alternative', 'alternatives', 'although', 'altogether', 'altruistic', 'alumni', 'alurralde', 'alvin', 'always', 'alysia', 'alzheimer', 'ambassador', 'ambitions', 'ambitious', 'amend', 'amended', 'amending', 'america', 'american', 'american-style', 'americana', 'americans', 'amid', 'amin', 'among', 'amount', 'amounted', 'amounts', 'amphobiles', 'amusing', 'an', 'analyst', 'analysts', 'analyze', 'ancient', 'ancillary', 'and', 'andrew', 'angeles', 'angelo', 'angels', 'anger', 'angered', 'angier', 'angle', 'anglia', 'anglian', 'angry', 'ankle', 'ann', 'anne', 'announce', 'announced', 'announcement', 'announcer', 'annoyed', 'annual', 'annually', 'another', 'answer', 'answers', 'anthony', 'anti-abortion', 'anti-abortionists', 'anti-china', 'anti-takeover', 'anticipated', 'anticipates', 'anticipating', 'antinori', 'antitrust-law', 'antonio', 'anxieties', 'anxious', 'any', 'anybody', 'anyone', 'anything', 'anywhere', 'apartment', 'apiece', 'apologize', 'apologizing', 'apology', 'apparently', 'appeal', 'appealing', 'appeals', 'appear', 'appeared', 'appears', 'appellate', 'apple', 'appliances', 'application', 'applications', 'applied', 'apply', 'appointed', 'appointment', 'appreciation', 'apprehensive', 'approach', 'approaches', 'appropriate', 'approval', 'approve', 'approved', 'approves', 'approximately', 'april', 'aptitude', 'aquino', 'arabia', 'arafat', 'arbitrage', 'architectural', 'architecture', 'are', 'area', 'areas', 'argentina', 'argentine', 'argue', 'argued', 'argues', 'arguing', 'argument', 'arguments', 'ariail', 'arising', 'ariz.', 'arizona', 'arlington', 'arm', 'arms', 'around', 'arrangement', 'arrest', 'arrival', 'arrived', 'arrows', 'arsenide', 'art', 'arthur', 'article', 'articles', 'artist', 'as', 'asada', 'asbestos', 'asbestos-related', 'asbestosis', 'ascribe', 'asia', 'asian', 'asians', 'ask', 'asked', 'asking', 'asks', 'aslacton', 'aspects', 'aspersions', 'aspires', 'assault', 'assemble', 'assembled', 'asserted', 'asserting', 'assertions', 'asset', 'asset-sale', 'assets', 'assigned', 'assist', 'assistance', 'assistant', 'assisted', 'associate', 'associated', 'associates', 'association', 'assume', 'assumed', 'assuming', 'assumption', 'assurance', 'assured', 'astonishment', 'astronomical', 'at', 'at&t', 'athletic', 'atlanta', 'atlanta-based', 'atlantic', 'attached', 'attack', 'attacking', 'attacks', 'attempt', 'attempting', 'attempts', 'attend', 'attendance', 'attended', 'attending', 'attention', 'attitude', 'attorney', 'attorney-client', 'attorneys', 'attract', 'attracted', 'attracting', 'attractions', 'attractive', 'attracts', 'attributes', 'auction', 'auctioned', 'auctions', 'audience', 'audiocassettes', 'audit', 'aug.', 'august', 'aurora', 'austere', 'australia', 'australian', 'austria', 'austrian', 'author', 'authorities', 'authority', 'authorized', 'authors', 'autions', 'auto', 'auto-safety', 'automatic', 'automation', 'automobile', 'automobiles', 'automotive', 'automotive-lighting', 'automotive-parts', 'autos', 'autumn', 'available', 'avenue', 'average', 'averaged', 'avoid', 'avrett', 'awarded', 'awarding', 'awards', 'aware', 'away', 'awful', 'awfully', 'b', 'b.', 'babcock', 'baby', 'back', 'backe', 'backed', 'backer', 'backlogs', 'backyard', 'bad', 'badly', 'bags', 'bailey', 'baker', 'balance', 'balanced', 'bald-faced', 'baldwin', 'balked', 'ball', 'ballplayers', 'ballroom', 'balls', 'baltimore', 'ban', 'bancorp', 'band', 'bang', 'bangkok', 'bank', 'banker', 'bankers', 'banking', 'bankroll', 'bankruptcy', 'banks', 'banned', 'banning', 'banque', 'banquet', 'bans', 'bar', 'barbara', 'barbaresco', 'barfield', 'bargain', 'baris', 'barking', 'barnett', 'barney', 'barnum', 'barred', 'barrel', 'barrels', 'barrier', 'barriers', 'bars', 'base', 'baseball', 'based', 'bases', 'basham', 'basic', 'basically', 'basis', 'bass', 'bat', 'bates', 'baton', 'battery-operated', 'batting', 'battle', 'battles', 'be', 'bearing', 'bearish', 'beat', 'beaten', 'beatles', 'beautiful', 'became', 'because', 'become', 'becomes', 'becoming', 'beds', 'been', 'beer-belly', 'before', 'beforehand', 'befuddled', 'began', 'begin', 'beginning', 'begins', 'begot', 'behalf', 'behaving', 'behavior', 'behemoth', 'behest', 'behind', 'beige', 'beijing', 'being', 'belfries', 'belfry', 'believe', 'believed', 'believes', 'bell', 'bell-ringer', 'bell-ringing', 'bellringers', 'bells', 'belong', 'belonging', 'belongs', 'below', 'belt', 'belts', 'benchmark', 'bend', 'beneficiaries', 'beneficiary', 'benefited', 'benefits', 'benevolent', 'benign', 'bentsen', 'berger', 'berliner', 'bermuda', 'bermuda-based', 'bernstein', 'berson', 'besides', 'best', 'best-seller', 'best-selling', 'besuboru', 'beta', 'beth', 'betrayer', 'better', 'betterment', 'between', 'beverly', 'bew', 'beyond', 'biannual', 'bias', 'bickering', 'bid', 'bidders', 'bidding', 'bids', 'big', 'big-ticket', 'big-time', 'bigger', 'biggest', 'bilateral', 'bill', 'billed', 'billings', 'billion', 'billionaire', 'billions', 'bills', 'bin', 'binders', 'biondi-santi', 'birmingham', 'biscayne', 'bit', 'bitterness', 'black', 'black-and-white', 'blacks', 'blackstone', 'blamed', 'blanc', 'blanchard', 'blancs', 'blank', 'bled', 'bless', 'blessing', 'blind', 'blinks', 'blip', 'block', 'blocked', 'blocks', 'bloody', 'blow', 'blue', 'board', 'boarding', 'boast', 'bob', 'boca', 'bodner', 'body', 'boeing', 'boesel', 'bold', 'bolduc', 'bolster', 'bond', 'bonds', 'bonnell', 'bonus', 'bonuses', 'book', 'booked', 'booklet', 'booklets', 'books', 'boom', 'boomers', 'booming', 'boone', 'boorse', 'boost', 'boosted', 'boosts', 'bordeaux', 'borders', 'borge', 'borrowed', 'borrowers', 'borrowing', 'boston', 'botched', 'both', 'bottle', 'bottles', 'bottom', 'bought', 'boulder', 'bout', 'boutique', 'bowed', 'bowery', 'bowes', 'box', 'boyfriends', 'boys', 'brace', 'brady', 'braidwood', 'brain', 'bramalea', 'branch', 'branches', 'brat', 'braun', 'brazil', 'breach', 'breakdown', 'breaker', 'breakers', 'breakfast', 'breaking', 'breaks', 'breathe', 'breeden', 'brenda', 'brent', 'bretz', 'brian', 'bricks', 'bridgestone/firestone', 'bridgeville', 'brief', 'briefing', 'bright', 'brightest', 'brilliant', 'bring', 'brings', 'britain', 'british', 'broad', 'broader', 'broke', 'broken', 'brokerage', 'brokers', 'bromwich', 'bronx', 'bronze', 'brooke', 'brooklyn', 'brought', 'brown', 'brownell', 'brownstein', 'brunei', 'brunello', 'brunswick', 'buck', 'buckle', 'budget', 'buffet', 'bugs', 'build', 'building', 'building-products', 'buildings', 'builds', 'buildup', 'built', 'built-from-kit', 'bulk', 'bull', 'bullets', 'bulls', 'bumkins', 'bundling', 'bunny', 'buoyed', 'burden', 'burdens', 'bureau', 'bureaucratic', 'burgundies', 'burgundy', 'burlap', 'burned', 'burt', 'buses', 'bush', 'busiest', 'business', 'businesses', 'businessman', 'businessmen', 'busloads', 'but', 'butler', 'butterfly', 'buttoned-down', 'buy', 'buy-back', 'buy-out', 'buyers', 'buying', 'by', 'byron', \"c'mon\", 'c-number_token', 'c.', 'c.j.b.', 'ca', 'cab', 'cabernet', 'cabernets', 'cabinet', 'cabs', 'cadet', 'calculate', 'calculations', 'calder', 'calif', 'calif.', 'california', 'call', 'called', 'callers', 'calling', 'calls', 'came', 'camera', 'camille', 'campaign', 'campaigner', 'campaigning', 'campaigns', 'campbell', 'campus', 'can', 'canada', 'canadian', 'cancer', 'cancer-causing', 'candela', 'candidate', 'candidates', 'canepa', 'cannell', 'capacity', 'capital', 'capital-gains', 'capitalist', 'capitol', 'capped', 'capsules', 'captivating', 'captive', 'capture', 'car', 'car-safety', 'carballo', 'carbide', 'card', 'cardboard', 'care', 'cared', 'career', 'careers', 'carefree', 'careful', 'carefully', 'caretaker', 'cargo', 'carillons', 'carla', 'carlos', 'carney', 'carolina', 'carried', 'carries', 'carry', 'carrying', 'cars', 'carson', 'cartoonist', 'cascading', 'case', 'cases', 'cash', 'cash-flow', 'cash-rich', 'cask', 'cast', 'casting', 'casts', 'cat', 'catch', 'catch-up', 'categories', 'category', 'caters', 'cathedral', 'cathryn', 'caught', 'cause', 'caused', 'causing', 'caution', 'cautiously', 'caveat', 'cbs', 'cdc', 'cds', 'cedric', 'ceiling', 'celebrate', 'cellar', 'cellars', 'cement', 'cent', 'centennial', 'center', 'centerbank', 'centers', 'central', 'cents', 'century', 'ceos', 'certain', 'certainly', 'certificate', 'certificates', 'certified', 'chabrol', 'chafic', 'chain', 'chaired', 'chairman', 'chalk', 'challenge', 'challenging', 'chamber', 'champagne', 'champagnes', 'chance', 'chandler', 'change', 'change-ringing', 'changed', 'changes', 'changing', 'channel', 'chaotic', 'chaplin', 'chapter', 'character', 'characterizing', 'characters', 'chardonnay', 'chardonnays', 'charge', 'charged', 'charges', 'charles', 'charlie', 'charlotte', 'charm', 'charts', 'chary', 'chase', 'chastised', 'chat', 'chateau', 'chauffeur', 'cheat', 'cheating', 'check', 'checkbook', 'checking', 'checks', 'cheerleaders', 'cheerleading', 'cheese', 'chefs', 'chemical', 'chemicals', 'chemplus', 'chevrolet', 'chicago', 'chicago-style', 'chief', 'chiefly', 'child', 'childish', 'children', 'chile', 'chilver', 'china', 'chinchon', 'chinese', 'chinese-american', 'chiodo', 'chip', 'chips', 'chocolate', 'choice', 'chong-sik', 'choose', 'chopped', 'chosen', 'christian', 'christopher', 'chronicle', 'chrysler', 'chrysotile', 'chuck', 'chunk', 'church', 'church-goers', 'churches', 'cigarette', 'cigarettes', 'cigna', 'circle', 'circuit', 'circuit-breaker', 'circulation', 'circulations', 'circumstances', 'cite', 'cited', 'cites', 'cities', 'citing', 'citizen', 'citizens', 'city', 'civilization', 'claim', 'claiming', 'claims', 'clamped', 'clara', 'clarified', 'clarify', 'clark', 'class', 'classed', 'classes', 'classic', 'classical', 'classics', 'classifications', 'classified', 'classmates', 'classroom', 'claude', 'clays', 'clean', 'cleaned', 'clear', 'clearing', 'clearly', 'clears', 'clemens', 'clerics', 'clerks', 'cleveland', 'clicked', 'client', 'clients', 'climate', 'climbed', 'climbing', 'clinton', 'clive', 'clobbered', 'close', 'close-up', 'closed', 'closed-end', 'closely', 'closeness', 'closer', 'cloud', 'clouds', 'club', 'clubs', 'clues', 'cluttered', 'co', 'co-chairman', 'co-developers', 'co-owner', 'co.', 'coaching', 'coal', 'coca-cola', 'coche-dury', 'cocky', 'cocoa', 'coconut', 'code', 'codified', 'cohesive', 'coincident', 'coincidental', 'cold', 'cole', 'coleman', 'collaborated', 'collapsed', 'collar', 'colleagues', 'collected', 'collecting', 'collection', 'collections', 'collective-bargaining', 'college', 'college-bowl', 'colleges', 'colo.', 'colonsville', 'colony', 'color', 'colorado', 'columbia', 'column', 'combat', 'combinations', 'combined', 'combines', 'combo', 'come', 'comedies', 'comes', 'comfort', 'comfortable', 'coming', 'command', 'commanded', 'comment', 'commenting', 'comments', 'commerce', 'commercial', 'commercials', 'commission', 'commit', 'commitment', 'commitments', 'committed', 'committee', 'committees', 'committing', 'commodities', 'commodity', 'commodore', 'common', 'commonwealth', 'communication', 'communications', 'communists', 'community', 'companies', 'company', 'comparable', 'compare', 'compared', 'compares', 'compatible', 'compel', 'compensate', 'compensation', 'compete', 'competed', 'competing', 'competition', 'competitions', 'competitive', 'competitor', 'competitors', 'compiled', 'complain', 'complained', 'complaining', 'complaint', 'complaints', 'complete', 'completed', 'completely', 'completeness', 'completion', 'compliance', 'complicate', 'complicated', 'composer', 'composite', 'composting', 'compound', 'comprehensive', 'compromise', 'computer', 'computer-aided', 'computer-driven', 'computer-generated', 'computer-system-design', 'computerize', 'computerized', 'computers', 'computing', 'comtes', 'concedes', 'concentrate', 'concentrated', 'concentrating', 'concentration', 'concept', 'concern', 'concerned', 'concerns', 'concession', 'concessions', 'concluded', 'condemned', 'condemning', 'conditional', 'conditions', 'conduct', 'conducting', 'conduit', 'conference', 'confidence', 'confidential', 'confines', 'confirmed', 'conflicts', 'conforms', 'confrontational', 'confronted', 'confuse', 'confused', 'conglomerate', 'congregation', 'congress', 'congressional', 'congressman', 'congressmen', 'conn', 'conn.', 'connecticut', 'connection', 'connections', 'consecutive', 'consensus', 'consent', 'consented', 'consider', 'considerable', 'considerably', 'consideration', 'considered', 'considering', 'consist', 'consists', 'consolidated', 'consomme', 'consonant', 'conspicuous', 'constituent', 'constitution', 'constraints', 'construction', 'consultant', 'consultants', 'consulting', 'consumer', 'consumer-driven', 'consumers', 'consumption', 'contacted', 'contacts', 'contain', 'contained', 'containers', 'contains', 'contemporary', 'contends', 'content', 'contests', 'continental', 'contingent', 'continually', 'continue', 'continued', 'continues', 'continuing', 'contract', 'contracted', 'contractor', 'contractors', 'contracts', 'contrary', 'contrast', 'contributed', 'contributing', 'contribution', 'contributions', 'contributors', 'control', 'controlled', 'controlling', 'controls', 'controversial', 'controversy', 'convenient', 'conventional', 'conversations', 'converted', 'convertible', 'converting', 'convey', 'convicted', 'conviction', 'convinced', 'cool', 'cooper', 'cooperation', 'coors', 'cop-killer', 'cope', 'copied', 'copies', 'copperweld', 'copycats', 'copyright', 'copyrights', 'corazon', 'core', 'corestates', 'corners', 'corp', 'corp.', 'corporate', 'corporations', 'correct', 'correcting', 'correll', 'correspondence', 'corridors', 'corrigan', 'corruption', 'corton-charlemagne', 'cosby', 'cosmetic', 'cosmopolitan', 'cost', 'costly', 'costs', 'cote', 'cotran', 'cotton', 'could', 'council', 'counseling', 'count', 'counter', 'counterattack', 'counterpart', 'counterparts', 'counterrevolutionary', 'counterweight', 'counting', 'countries', 'country', 'counts', 'county', 'couple', 'coupled', 'couples', 'courage', 'course', 'court', 'court-ordered', 'courter', 'courtroom', 'courts', 'cover', 'covered', 'covers', 'coxon', 'cozy', 'crack', 'crackdown', 'craft', 'crane', 'cranked', 'crash', 'crashes', 'cray', 'cray-number_token', 'craze', 'create', 'created', 'creating', 'creation', 'creativity', \"creator's\", 'credibility', 'credit', 'creditor', 'creditors', 'credits', 'creek', 'crew', 'crews', 'crib', 'crime', 'criminal', 'crippled', 'crisis', 'cristal', 'critical', 'criticism', 'criticized', 'critics', 'crocidolite', 'cross', 'crossed', 'crossing', 'crowd', 'crowded', 'crown', 'cru', 'crucial', 'crude', 'cruising', 'crunch', 'crushed', 'cry', 'ctb', 'ctbs', 'cues', 'cult', 'cultivated', 'cultural', 'curb', 'cure', 'curled', 'curly', 'currencies', 'currency', 'current', 'currently', 'curriculum', 'curry', 'curse', 'custom-chip', 'customer', 'customers', 'cut', 'cutbacks', 'cute', 'cutrer', 'cutthroat', 'cutting', 'cuvees', 'cycles', 'cyclical', 'czech', 'czechoslovakia', 'd.', 'd.c.', 'dahl', 'daily', 'dairy', 'daiwa', 'dale', 'dallara', 'dallas', 'dam', 'damage', 'damaged', 'damages', 'damn', 'dams', 'dan', 'dana-farber', 'dances', 'dancing', 'danforth', 'daniel', 'daniels', 'danube', 'danville', 'dark', 'darkhorse', 'darrell', 'dashes', 'data', 'date', 'dating', 'davenport', 'david', 'davies', 'davis', 'dawn', 'day', 'days', 'ddb', 'de', 'dead', 'dead-eyed', 'deadline', 'deadwood', 'deal', 'dealers', 'deals', 'dean', 'deane', 'death', 'deaths', 'debacle', 'debate', 'debentures', 'deborah', 'debt', 'debts', 'debut', 'dec.', 'decade', 'decades', 'december', 'deceptive', 'decide', 'decided', 'decides', 'decision', 'decisions', 'declaration', 'declare', 'declared', 'decline', 'declined', 'declines', 'declining', 'decorated', 'decrease', 'decried', 'deem', 'deemed', 'deeply', 'default', 'defeat', 'defeats', 'defendant', 'defended', 'defense', 'deficit', 'define', 'defined', 'definitive', 'defuse', 'degenerative', 'degree', 'degrees', 'del', 'del.', 'delay', 'delegates', 'delete', 'deliver', 'delivering', 'delivery', 'dell', 'deluxe', 'delwin', 'demand', 'demanding', 'demise', 'democrat', 'democratic', 'democrats', 'demographic', 'demonstrating', 'demonstrations', 'demonstrators', 'deng', 'denial', 'denied', 'denies', 'dennis', 'denominator', 'denver', 'deny', 'denying', 'department', 'departure', 'depend', 'depended', 'depending', 'deposit', 'depositary', 'deposits', 'deposits-a', 'depressed', 'deputy', 'deregulation', 'derek', 'derel', 'derivatives', 'deryck', 'desai', 'descending', 'describe', 'described', 'describes', 'deserve', 'design', 'designated', 'designed', 'designer', 'designing', 'desirable', 'desired', 'desktop', 'desperately', 'despite', 'dessert', 'desultory', 'detail', 'detailed', 'details', 'detective-story', 'deteriorated', 'deteriorating', 'determined', 'deterring', 'detroit', 'devastating', 'develop', 'developed', 'developing', 'development', 'developments', 'develops', 'device', 'devices', 'devised', 'devon', 'devote', 'devoted', 'dexterity', 'diabetes', 'diagnosed', 'diagram', 'dialogue', 'diamond', 'dick', 'did', 'die', 'died', 'differ', 'difference', 'differences', 'different', 'differential', 'difficult', 'dilemma', 'dill', 'diming', 'diminish', 'dingell', 'dinkins', 'dinner', 'diplomacy', 'diplomatic', 'diplomats', 'direct', 'direct-investment', 'directing', 'direction', 'directly', 'director', 'directors', 'dirty', 'disaffected', 'disagree', 'disagreeable', 'disappears', 'disappointed', 'disappointment', 'disapprove', 'discarded', 'disciplinary', 'disciplined', 'disclosed', 'disclosing', 'disclosure', 'discontent', 'discontinue', 'discontinuing', 'discordant', 'discos', 'discount', 'discounts', 'discourage', 'discouraging', 'discovered', 'discredit', 'discretionary', 'discuss', 'discussed', 'discussing', 'discussions', 'disease', 'diseases', 'disembodied', 'disgorge', 'disk', 'dismay', 'dismissal', 'dismissed', 'disparate', 'display', 'disproportionate', 'dispute', 'disputed', 'disputes', 'disregard', 'disruption', 'disruptive', 'dissident', 'dissolves', 'distasteful', 'distinguished', 'distorted', 'distribution', 'distributor', 'district', 'districts', 'disturbing', 'disturbs', 'diversification', 'diversified', 'diversify', 'diversifying', 'diversionary', 'divest', 'divided', 'dividend', 'dividends', 'division', 'do', 'doak', 'dobson', 'docile', 'doctorate', 'doctors', 'document', 'documents', 'dodge', 'doerflinger', 'does', 'dogs', 'doing', 'dollar', 'dollar-denominated', 'dollar-yen', 'dollars', 'dolphin', 'dom', 'domaine', 'domestic', 'dominance', 'dominating', 'domination', 'dominion', 'dominus', 'dompierre', 'donald', 'donaldson', 'done', 'donoghue', 'donor', 'doonesbury', 'door', 'doors', 'dormitory', 'dorothy', 'double', 'double-digit', 'doubled', 'doubt', 'douglas', 'dow', 'down', 'downfall', 'downright', 'downtown', 'downturn', 'downward', 'dozen', 'dozens', 'dr.', 'drag-down', 'drain', 'dramatic', 'dramatically', 'draw', 'drawbacks', 'drawing', 'drawn', 'dreadful', 'dreamed', 'dreamt', 'drearier', 'dressed', 'dresser', 'dreyfus', 'drift', 'drifted', 'drink', 'drinking', 'drinks', 'driscoll', 'driskill', 'drive', 'drivers', 'drives', 'driving', 'drobnick', 'drooled', 'drop', 'drop-off', 'dropped', 'drove', 'drug', 'drums', 'dry', 'du', 'duchossois', 'duckling', 'due', 'dugdale', 'dumbfounded', 'dummies', 'dumped', 'dumpster', 'dunn', 'durable', 'durable-goods', 'during', 'dust', 'dust-up', 'dusty', 'dutch', 'duties', 'duty-free', 'dwindling', 'dynamics', 'e.', 'e.c.', 'each', 'eager', 'eagleton', 'earle', 'earlier', 'earliest', 'early', 'earn', 'earned', 'earnings', 'earns', 'ease', 'eased', 'eases', 'easier', 'easily', 'easing', 'east', 'eastern', 'easy', 'eat', 'eating', 'eaton', 'eclectic', 'economic', 'economical', 'economics', 'economies', 'economist', 'economists', 'economy', 'ed', 'edge', 'edison', 'editions', 'editor', 'editorial', 'editorials', 'editors', 'educated', 'education', 'educational', 'educators', 'edward', 'effect', 'effective', 'effectively', 'effects', 'efficiencies', 'effort', 'efforts', 'eight', 'eight-count', 'eight-month', 'eighth', 'einhorn', 'either', 'elaborate', 'elderly', 'elected', 'election', 'elections', 'electric', 'electric-utility', 'electricity', 'electronic', 'electronics', 'element', 'elevators', 'eligible', 'eliminate', 'eliminated', 'eliminates', 'elimination', 'elisabeth', 'elite', 'elizabeth', 'elliott', 'elmhurst', 'else', 'elsevier', 'elsewhere', 'elusive', 'embarrassing', 'embassy', 'embroiled', 'emerge', 'emergencies', 'emerges', 'emerging', 'emigrate', 'emile', 'emotions', 'emphasis', 'employed', 'employee', 'employees', 'employers', 'employment', 'employs', 'empowered', 'empty', 'enabled', 'enabling', 'enact', 'enacted', 'encircling', 'enclosed', 'encounter', 'encourage', 'encouraged', 'encourages', 'encroaching', 'end', 'ended', 'ending', 'endless', 'endorsed', 'ends', 'energetic', 'energy', 'energy-services', 'enforce', 'enforcement', 'engaged', 'engaging', 'engineer', 'engineered', 'engineering', 'engineers', 'england', 'english', 'enhanced', 'enjoying', 'enlarged', 'enormous', 'enormously', 'enough', 'enraged', 'enright', 'enrollment', 'ensembles', 'ensnarled', 'ensrud', 'entangled', 'enter', 'entered', 'entering', 'enterprise', 'enters', 'entertain', 'entertaining', 'entertainment', 'enthusiasm', 'entice', 'enticed', 'entire', 'entirely', 'entitled', 'entitles', 'entrance', 'entrants', 'entrench', 'entrepreneur', 'enviable', 'environment', 'environmental', 'environmentalists', 'environments', 'envoy', 'episodes', 'equal', 'equal-opportunity', 'equally', 'equals', 'equip', 'equipment', 'equipped', 'equity', 'equivalent', 'era', 'erasures', 'erbamont', 'eric', 'erode', 'errors', 'erudite', 'escalated', 'escaped', 'escort', 'escrow', 'especially', 'espouse', 'essays', 'essentially', 'esso', 'established', 'establishing', 'estate', 'estates', 'estimated', 'estimates', 'estimation', 'eternal', 'ethel', 'ethical', 'ethics', 'eugene', 'europe', 'european', 'evaluated', 'evaluating', 'evaporated', 'even', 'evening', 'evenly', 'evensong', 'event', 'events', 'eventually', 'ever', 'every', 'everybody', 'everyday', 'everyone', 'everything', 'everywhere', 'evidence', 'evident', 'evoke', 'evolution', 'exact', 'exactly', 'examination', 'example', 'examples', 'exceed', 'exceedingly', 'excellence', 'except', 'exception', 'exceptional', 'exceptionally', 'excess', 'excesses', 'excessive', 'excessively', 'exchange', 'exchanges', 'exchanging', 'excise', 'excited', 'exciting', 'excluding', 'exclusion', 'exclusive', 'exclusively', 'execs', 'execute', 'executed', 'executing', 'executive', 'executives', 'exempt', 'exercisable', 'exercise', 'exercised', 'exhaust', 'exhausted', 'exhibited', 'exhibition', 'exist', 'existed', 'existence', 'existing', 'exists', 'exit', 'exits', 'expand', 'expanded', 'expanding', 'expands', 'expansion', 'expect', 'expectations', 'expected', 'expecting', 'expects', 'expedited', 'expelled', 'expenditures', 'expenses', 'expensive', 'experience', 'experts', 'expire', 'expired', 'expires', 'explain', 'explained', 'explains', 'explanatory', 'exploit', 'explorer', 'explosion', 'explosive', 'export', 'export-oriented', 'exports', 'exposed', 'exposure', 'exposures', 'express', 'expressed', 'expunged', 'extend', 'extended', 'extension', 'extent', 'external', 'extra', 'extramarital', 'extraordinary', 'extremely', 'exxon', 'eye', 'eyes', 'f-series', 'f.', 'f.h.', 'f.w.', 'fabled', 'fabricate', 'fabricator', 'facade', 'face', 'faced', 'faces', 'facial', 'facility', 'facing', 'fact', 'factor', 'factories', 'factors', 'factory', 'faculty', 'faded', 'fail', 'failed', 'failing', 'fails', 'failure', 'faint', 'fainting', 'fair', 'fairly', 'fairness', 'faithful', 'fall', 'fallen', 'falling', 'familiar', 'familiarization', 'family', 'family-planning', 'fancy', 'fanfare', 'fang', 'fannie', 'fans', 'far', 'fare', 'fared', 'fargo', 'farren', 'fashion', 'fast', 'fast-food', 'faster', 'fastest', 'fat', 'fatalities', 'father', 'father-in-law', 'fattened', 'faulding', 'fault', 'faultlessly', 'favor', 'favorable', 'favored', 'favorite', 'fawning', 'fax', 'feared', 'fearful', 'fears', 'feature', 'featured', 'features', 'featuring', 'feb.', 'february', 'fed', 'federal', 'federally', 'federation', 'fee', 'feed', 'feel', 'feeling', 'feelings', 'feels', 'fees', 'feet', 'fell', 'fellow', 'fellowship', 'felony', 'felt', 'felten', 'female', 'ferc', 'fernando', 'fetal', 'fetal-tissue', 'feudal', 'few', 'fewer', 'fiber', 'fibers', 'field', 'fields', 'fierce', 'fifteen', 'fifth', 'fifth-grade', 'fight', 'fighters', 'fighting', 'fights', 'figure', 'figures', 'file', 'filed', 'filing', 'fill', 'filled', 'filling', 'fills', 'film', 'filmed', 'films', 'filter', 'filters', 'final', 'finally', 'finance', 'financed', 'financial', 'financially', 'financing', 'find', 'finding', 'findings', 'finds', 'fine', 'fined', 'finest', 'finished', 'finmeccanica', 'fire', 'fired', 'fires', 'firings', 'firm', 'firms', 'first', 'first-time', 'fiscal', 'fishman', 'fit', 'fits', 'five', 'five-day', 'five-inch', 'five-point', 'five-year', 'fixed', 'fixed-rate', 'fixtures', 'fla.', 'flag', 'flap', 'flashy', 'flat', 'flatulent', 'fledgling', 'flexibility', 'flightiness', 'floating-rate', 'flood', 'flooded', 'floor', 'florida', 'florio', 'flourish', 'flow', 'flows', 'floyd', 'fluctuation', 'fluent', 'flush', 'foam', 'focus', 'focused', 'focusing', 'fold', 'folks', 'followed', 'following', 'follows', 'fond', 'food', 'food-shop', 'foods', 'foot', 'football', 'for', 'force', 'forced', 'forces', 'forcing', 'ford', 'forecast', 'forecasting', 'forecasts', 'foreign', 'foreign-led', 'foreign-stock', 'foreigners', 'forest-product', 'forest-products', 'forgiven', 'forgotten', 'form', 'formal', 'format', 'formed', 'former', 'formerly', 'forms', 'formula', 'forthcoming', 'fortune', 'forum', 'forward', 'foster', 'fought', 'foul', 'found', 'foundation', 'foundations', 'founded', 'founder', 'foundering', 'fountain', 'four', 'four-color', 'four-year', 'four-year-old', 'fourth', 'fraction', 'fractionally', 'fragile', 'fragmentation', 'framework', 'france', 'frances', 'francis', 'francisco', 'frank', 'frankly', 'frantic', 'fraud', 'fred', 'frederick', 'free', 'free-lance', 'freedom', 'fremantle', 'french', 'frenzy', 'frequency', 'frequently', 'fresh', 'freshman', 'fret', 'fretted', 'friday', 'friend', 'friendly', 'friends', 'friendship', 'from', 'front', 'front-seat', 'fronts', 'frozen', 'frustrating', 'ft-se', 'fuel', 'fueled', 'fueling', 'fuentes', 'fuji', 'fujitsu', 'fulbright', 'full', 'full-length', 'fuller', 'fully', 'fumes', 'fuming', 'functions', 'fund', 'funded', 'funding', 'fundraising', 'funds', 'funny', 'furious', 'furniture', 'furor', 'further', 'furukawa', 'future', 'futures', 'futures-related', 'g.', 'ga.', 'gaf', 'gain', 'gained', 'gaining', 'gains', 'gaithersburg', 'gaja', 'galling', 'gallium', 'game', 'games', 'gangs', 'garage', 'garbage', 'gardner', 'garry', 'gary', 'gas', 'gates', 'gauge', 'gauges', 'gauging', 'gave', 'gayle', 'gelatin', 'genel', 'general', 'generalized', 'generally', 'generate', 'generations', 'genes', 'genie', 'gentle', 'genuine', 'geography', 'geometrical', 'george', 'georgetown', 'georgia', 'georgia-pacific', 'gerald', 'gerard', 'gerhard', 'german', 'germans', 'germany', 'get', 'get-out-the-vote', 'gets', 'getting', 'ghkm', 'ghs', 'giant', 'giants', 'gift', 'gifts', 'gillespie', 'gingl', 'ginsberg', 'giraud', 'girl', 'girlfriend', 'giuliani', 'give', 'giveaways', 'given', 'gives', 'giving', 'glamorize', 'glass', 'glauber', 'glendale', 'glenham', 'glenn', 'global', 'globally', 'globe', 'gloomy', 'glory', 'go', 'goal', 'god', 'goes', 'going', 'gold', 'goldinger', 'goldman', 'gone', 'good', 'good-hearted', 'good-natured', 'goode', 'goodies', 'goodman', 'goods', 'goody', 'gop', 'got', 'gotta', 'gotten', 'gov.', 'goverment', 'government', 'government-certified', 'government-funded', 'governor', 'governors', 'grace', 'grade', 'grader', 'graders', 'gradual', 'gradually', 'graduate', 'graduated', 'graduates', 'graham', 'grand', 'grandfather', 'grandsire', 'grandstander', 'grange', 'grant', 'grants', 'grapes', 'graphs', 'great', 'greater', 'greatest', 'greatly', 'greece', 'green', 'greenmailer', 'greenville', 'greenwich', 'greer', 'gregory', 'grew', 'grgich', 'griffin', 'gringo', 'groton', 'groucho', 'ground', 'group', 'groups', 'growing', 'grown', 'grows', 'growth', 'growths', 'guaranteed', 'guards', 'gubernatorial', 'guest', 'guests', 'guffey', 'guided', 'guigal', 'guild', 'guilty', 'guinea', 'gulf', 'guns', 'gunship', 'guys', 'gyrations', 'h.', 'h.n.', 'had', 'hahn', 'hair', 'hale', 'half', 'half-hour', 'halls', 'hallwood', 'halt', 'halts', 'halve', 'hamilton', 'hammerton', 'hammond', 'hampered', 'hampshire', 'hampton', 'hand', 'handful', 'handle', 'handled', 'handling', 'hands', 'haney', 'hangs', 'happen', 'happening', 'happens', 'happier', 'happy', 'hara', 'harass', 'harassment', 'harbinger', 'harcourt', 'hard', 'hard-charging', 'hard-drinking', 'hard-hitting', 'harder', 'hardly', 'hardware', 'harm', 'harmony', 'harms', 'harold', 'harped', 'harpo', 'harris', 'harsh', 'harshly', 'hartford', 'haruki', 'harvard', 'has', 'hatch', 'haul', 'hauled', 'haut-brion', 'have', 'haven', 'having', 'hawaiian', 'hawke', 'hay', 'hayes', 'hayne', 'hazardous', 'he', 'head', 'headquarters', 'headrests', 'heads', 'health', 'healthy', 'heard', 'hearing', 'heart', 'heartland', 'heated', 'heatherington', 'heating', 'heavily', 'heavy', 'heavy-duty', 'hefty', 'hegemony', 'heidelberg', 'heightened', 'heights', 'held', 'helm', 'help', 'helped', 'helping', 'henderson', 'henry', 'her', 'herald', 'here', 'heritage', 'hermitage', 'hero', 'herrington', 'herself', 'hhs', 'hid', 'hierarchical', 'high', 'high-balance', 'high-level', 'high-priced', 'high-quality', 'high-rate', 'high-rise', 'high-stakes', 'high-tech', 'high-technology', 'high-yield', 'higher', 'higher-salaried', 'highest', 'highest-pitched', 'highlight', 'highly', 'highway', 'hill', 'hills', 'him', 'himself', 'hint', 'hire', 'hired', 'hiroshi', 'hiroshima', 'his', 'historic', 'historical', 'historically', 'history', 'hit', 'hitachi', 'hitter', 'hitting', 'hobbyists', 'hoffman', 'hold', 'holder', 'holders', 'holding', 'holdings', 'holds', 'hole', 'holidays', 'hollingsworth', 'home', 'home-market', 'homebrew', 'homeless', 'homes', 'homework', 'homosexual', 'hong', 'honor', 'honorably', 'honors', 'hook', 'hoopla', 'hoosier', 'hope', 'hoped', 'hopefully', 'hopes', 'hormats', 'horsham', 'hospitable', 'hospital', 'hospitals', 'host', 'hostage', 'hosted', 'hostile', 'hostility', 'hot', 'hotel', 'hotels', 'hottest', 'houghton', 'hour', 'hours', 'house', 'household', 'houses', 'houston', 'how', 'how-to', 'however', 'hubbard', 'hudnut', 'hudson', 'huge', 'human', 'humans', 'humble', 'hummerstone', 'hundred', 'hundreds', 'hung', 'hungary', 'huntington', 'huntsville', 'huppert', 'hurdles', 'hurley', 'hurt', 'hurting', 'husband', 'hustlers', 'hutton', 'huxtable', 'hydraulically', 'hypocrisy', 'i', 'i.', 'ian', 'ibc', 'ibm', 'ichiro', 'idea', 'ideas', 'identified', 'identify', 'identities', 'identity-management', 'ideological', 'idiomatic', 'if', 'ignoring', 'ii', 'iii', 'ill', 'ill.', 'illegal', 'illegally', 'illinois', 'illuminating', 'ilminster', 'image', 'images', 'imaginative', 'imagine', 'imbalances', 'immediate', 'immediately', 'imminent', 'impact', 'impart', 'impartial', 'impediments', 'impending', 'imperative', 'implant', 'implication', 'implications', 'implicit', 'implies', 'imply', 'import', 'important', 'imported', 'imports', 'impose', 'imposed', 'imposing', 'impossible', 'impressed', 'impression', 'impressive', 'improbable', 'improper', 'improve', 'improved', 'improvement', 'improvements', 'improves', 'improving', 'impudent', 'imsai', 'in', 'inaccurate', 'inaccurately', 'inadequacy', 'inadequate', 'inappropriate', 'inauspicious', 'inc', 'inc.', 'incentive', 'incentive-bonus', 'incest', 'inched', 'inches', 'inching', 'incident', 'include', 'included', 'includes', 'including', 'income', 'incomplete', 'incorporated', 'increase', 'increased', 'increases', 'increasing', 'increasingly', 'incredible', 'incurred', 'indeed', 'indefinitely', 'independent', 'index', 'index-arbitrage', 'index-options', 'index-related', 'india', 'indiana', 'indianapolis', 'indicate', 'indicated', 'indicates', 'indicator', 'indicators', 'indictment', 'indirect', 'individual', 'individuals', 'indonesia', 'indulging', 'industrial', 'industrial-production', 'industrialized', 'industrials', 'industries', 'industry', 'industry-wide', 'inferences', 'inflated', 'inflation', 'inflationary', 'influence', 'influential', 'informally', 'information', 'infringed', 'infusion', 'ingersoll-rand', 'inherited', 'inheritor', 'initial', 'initialing', 'initially', 'initiated', 'initiative', 'injury', 'inkling', 'inner', 'inner-city', 'innuendoes', 'inquiry', 'inside', 'insiders', 'insidious', 'insight', 'insist', 'insisted', 'insistence', 'insists', 'insolvency', 'inspirational', 'inspired', 'installed', 'installing', 'installment', 'instance', 'instances', 'instead', 'institute', 'instituted', 'institutes', 'institution', 'institutional', 'institutions', 'instruction', 'instruments', 'insurance', 'insurer', 'integra', 'integra-a', 'integrated', 'integration', 'intellectual', 'intellectual-property', 'intelligence', 'intended', 'intense', 'intensity', 'intent', 'intention', 'interbank', 'interest', 'interest-bearing', 'interested', 'interesting', 'interests', 'interference', 'interim', 'interjects', 'intermediate', 'internal', 'international', 'internatonal', 'interpublic', 'interrogated', 'interrogation', 'interstate', 'intertitles', 'intervention', 'interventions', 'interview', 'interviewed', 'interviews', 'into', 'intoxication', 'intricate', 'introduce', 'introduced', 'introducing', 'introduction', 'invades', 'invariably', 'invent', 'invented', 'invention', 'inventiveness', 'inventories', 'inverted', 'invest', 'invested', 'investigating', 'investigation', 'investigations', 'investing', 'investment', 'investments', 'investor', 'investor-relations', 'investors', 'invests', 'involve', 'involved', 'involves', 'involving', 'iowa', 'iran/contra', 'iras', 'ire', 'irony', 'irs', 'is', 'isabelle', 'island', 'islands', 'issue', 'issued', 'issues', 'issuing', 'it', 'italian', 'italy', 'items', 'itoh', 'its', 'itself', 'ix', 'j.', 'j.l.', 'j.p.', 'jack', 'jackson', 'jacksonville', 'jacob', 'jaguar', 'jail', 'jalaalwalikraam', 'jam', 'jamaica', 'james', 'jan.', 'january', 'japan', 'japanese', 'jay', 'jefferson', 'jeffrey', 'jennison', 'jenrette', 'jeopardizing', 'jeremy', 'jerritts', 'jerry', 'jersey', 'jersey-based', 'jet', 'jews', 'jim', 'jitters', 'joanne', 'job', 'jobs', 'joe', 'john', 'johnny', 'johnson', 'join', 'joined', 'joining', 'joins', 'joint', 'joint-venture', 'jointly', 'jones', 'joseph', 'jostle', 'journal', 'journalistic', 'journalists', 'jovanovich', 'joy', 'joys', 'jr', 'jr.', 'judge', 'judged', 'judges', 'judging', 'judgments', 'judicial', 'judiciary', 'judie', 'juggernaut', 'jugglers', 'july', 'jump', 'jumped', 'jumping', 'june', 'junk-bond', 'jurisdictional', 'jury', 'just', 'justice', 'justify', 'justifying', 'juvenile', 'k.', 'kalipharma', 'kaminski', 'kane', 'kansas', 'kappa', 'karl', 'kathryn', 'katzenstein', 'kawasaki', 'kean', 'kearny', 'keehn', 'keep', 'keeping', 'keeps', 'keidanren', 'kelli', 'kenneth', 'kensington', 'kent', 'kentucky', 'kept', 'kerensky', 'ketchum', 'key', 'keyboards', 'kicked', 'kicker', 'kidnapper', 'kidnapping', 'kidney', 'kids', 'kill', 'killed', 'killeen', 'killing', 'killings', 'kind', 'kindergarten', 'kingdom', 'kirkpatrick', 'kit', 'kits', 'klauser', 'klein', 'kligman', 'knapp', 'knew', 'knife', 'knight', 'knitted', 'knocked', 'know', 'knowing', 'knowledge', 'knowledgeable', 'known', 'knowns', 'knows', 'kodansha', 'koito', 'kondo', 'kong', 'korea', 'kuala', 'kuhns', 'kuvin', 'ky.', 'l.', 'l.p.', 'la', 'la.', 'lab', 'label', 'labor', 'labor-intensive', 'lack', 'lacked', 'lackluster', 'lady', 'lafite-rothschild', 'lagging', 'laid', 'lake', 'lancaster', 'land', 'landfill', 'landing', 'landis', 'landonne', 'landor', 'lane', 'langner', 'language', 'language-housekeeper', 'lap', 'lap-shoulder', 'lapses', 'large', 'largely', 'larger', 'largest', 'larry', 'las', 'lasalle', 'laser', 'last', 'lasted', 'lasting', 'late', 'lately', 'later', 'latest', 'latin', 'latour', 'lauded', 'lauderhill', 'laughing', 'launch', 'launched', 'laura', 'laurels', 'law', 'lawmakers', 'laws', 'lawsuit', 'lawsuits', 'lawyer', 'lawyers', 'lay', 'le', 'lead', 'leader', 'leaders', 'leading', 'leap', 'leapt', 'learned', 'learning', 'leases', 'leasing', 'least', 'leave', 'leaves', 'leaving', 'led', 'lee', 'leeway', 'lefcourt', 'left', 'legal', 'legend', 'legislation', 'legislative', 'legislators', 'lehman', 'leigh', 'leinonen', 'leming', 'lend-lease', 'lender', 'length', 'lengthen', 'lengthened', 'lent', 'leo', 'leroy', 'lesions', 'less', 'less-serious', 'lessen', 'lessening', 'lesser', 'lesson', 'let', 'letter', 'letters', 'letting', 'level', 'leveling', 'levels', 'lewis', 'lezovich', 'li', 'liberals', 'liberation', 'liberty', 'library', 'license', 'licensed', 'licensing', 'lieutenant', 'life', 'life-insurance', 'life-style', 'lift', 'lifted', 'lifting', 'light', 'light-truck', 'lighter', 'lighthouse', 'lights', 'like', 'likelihood', 'likely', 'limit', 'limited', 'limited-partnership', 'limits', 'linda', 'line', 'link', 'linked', 'links', 'lion', 'liquid', 'list', 'listed', 'listing', 'litany', 'literacy', 'literary', 'litigation', 'little', 'live', 'lives', 'living', 'lizhi', 'lloyd', 'load', 'loaded', 'loan', 'loans', 'lobo', 'lobster', 'local', 'locally', 'located', 'lock', 'locked', 'loews', 'lofty', 'logic', 'logjam', 'logo', 'london', 'london-based', 'long', 'long-term', 'long-time', 'longer', 'longest', 'longevity', 'longstanding', 'longwood', 'look', 'looking', 'loom', 'looming', 'loose', 'lord', 'lore', 'lorillard', 'los', 'losing', 'loss', 'losses', 'lost', 'lot', 'lottery', 'louis', 'louisiana', 'louisville', 'loved', 'loveliest', 'lovely', 'lover', 'low', 'low-ability', 'low-altitude', 'low-ball', 'low-cost', 'low-priced', 'low-tech', 'lowe', 'lower', 'lower-priority', 'lowered', 'lowering', 'lowest', 'loyal', 'loyalty', 'lsi', 'lt.', 'ltd', 'ltd.', 'ltv', 'luce', 'luck', 'lucky', 'lucrative', 'lufkin', 'lumpur', 'lunch', 'lung', 'lungs', 'lure', 'lying', 'lynch', 'lyrics', 'm.', 'macdonald', 'macheski', 'machine', 'machine-gun-toting', 'machinery', 'machines', 'macmillan', 'macmillan/mcgraw', 'macmillan/mcgraw-hill', 'made', 'madison', 'madly', 'mae', 'magazine', 'magazines', 'magicians', 'magna', 'magnitude', 'mail', 'mailed', 'mailing', 'main', 'mainframe', 'mainland', 'mainly', 'maintained', 'maintaining', 'maintenance', 'major', 'majority', 'makato', 'make', 'maker', 'makers', 'makes', 'making', 'malaysia', 'malcolm', 'male', 'male-dominated', 'male-only', 'males', 'malignant', 'malizia', 'man', 'managed', 'management', 'manager', 'managers', 'manages', 'managing', 'manchester', 'manfred', 'manhattan', 'mania', 'manipulate', 'manner', 'manually', 'manufacture', 'manufactured', 'manufacturer', 'manufacturers', 'manufacturing', 'many', 'map', 'mara', 'marbles', 'marc', 'march', 'marchand', 'marchese', 'marching', 'marder', 'marge', 'margins', 'marie', 'marie-louise', 'marietta', 'marina', 'marion', 'mark', 'markdown', 'market', 'market-share', 'marketer', 'marketing', 'marketing-communications', 'marketplace', 'markets', 'markey', 'marks', 'markup', 'marriages', 'marshall', 'martin', 'marty', 'martyr', 'marvelously', 'mary', 'maryland', 'mason', 'mass', 'mass.', 'massachusetts', 'massacre', 'master', 'match', 'matched', 'matches', 'matching', 'material', 'materialistic', 'materialize', 'materials', 'mathematical', 'mathematics', 'mather', 'mating', 'matter', 'matters', 'mature', 'maturing', 'maturities', 'maturity', 'maughan', 'maximum', 'maxwell', 'may', 'maybe', 'mayer', 'mayland', 'mayor', 'maytag', 'mazda', 'maze', 'mcalpine', 'mcauley', 'mcdermott', 'mcfall', 'mcgraw-hill', 'mcleod', 'md.', 'me', 'meal', 'mean', 'meaning', 'meaningful', 'means', 'meant', 'meanwhile', 'measure', 'measured', 'measurement', 'measures', 'mechanical', 'mechanically', 'mechanism', 'mechanisms', 'media', 'medical', 'medicine', 'medium-sized', 'meet', 'meeting', 'meetings', 'meets', 'mehrens', 'meinders', 'melamed', 'member', 'members', 'membership', 'memories', 'memorize', 'memory', 'memphis', 'men', 'mend', 'menem', 'mental', 'mention', 'merc', 'mercantile', 'mercer', 'merchandise', 'merchant', 'merchants', 'mere', 'merely', 'merge', 'merged', 'merger', 'merger-related', 'merit', 'merrick', 'merrill', 'mesnil', 'mesothelioma', 'message', 'messrs.', 'met', 'metals', 'methods', 'metric', 'metropolitan', 'mexican', 'mexico', 'miami', 'mich.', 'michael', 'michaels', 'michigan', 'michio', 'mickey', 'microcomputers', 'micronite', 'microphone', 'microwave', 'mid-number_tokens', 'mid-october', 'mid-size', 'middle', 'midnight', 'midtown', 'midvale', 'midwest', 'midyear', 'mifflin', 'might', 'mignon', 'miguel', 'mike', 'miklos', 'miles', 'milestone', 'milestones', 'military', 'milk', 'milked', 'miller', 'million', 'millions', 'milne', 'mind-boggling', 'minimal', 'minimum', 'mining', 'mininum-wage', 'minister', 'ministers', 'ministry', 'minivans', 'minn.', 'minneapolis', 'minneapolis-based', 'minor', 'minority', 'minus', 'minute', 'minutes', 'mired', 'mirror', 'mirrors', 'misdemeanor', 'miss.', 'mission', 'mistake', 'mistakes', 'mistrials', 'miti', 'mitsubishi', 'mitsui', 'mixed', 'mo', 'mo.', 'mobile', 'mobster', 'mode', 'model', 'models', 'modems', 'moderate', 'moderated', 'modern', 'modern-day', 'modest', 'modestly', 'modification', 'modifications', 'modify', 'moleculon', 'mollified', 'moment', 'mona', 'monchecourt', 'monday', 'monetary', 'money', 'money-center', 'money-fund', 'money-market', 'monied', 'monitor', 'monopolize', 'monster', 'mont', 'montedison', 'month', 'monthly', 'months', 'monticello', 'moons', 'moore', 'morale', 'morale-damaging', 'moratorium', 'morbidity', 'more', 'more-efficient', 'moreover', 'morgan', 'morita', 'morning', 'mortgage', 'mortgage-backed', 'mortgage-based', 'mortimer', 'moscow', 'mossman', 'most', 'mostly', 'mother', 'motion', 'motives', 'motor', 'mount', 'mounted', 'mousseline', 'mouth-up', 'move', 'moved', 'movement', 'moves', 'movie', 'movies', 'moving', 'mr.', 'mrs', 'mrs.', 'ms.', 'much', 'mudslinging', 'muffled', 'mulford', 'multibillion-dollar', 'multilevel', 'multinationals', 'mundane', 'municipal', 'municipalities', 'municipality', 'murakami', 'murder', 'murdered', 'murray', 'muscolina', 'museum', 'mushy', 'music', 'must', 'mutual', 'my', 'myriad', 'myron', \"n't\", 'n.', 'n.c', 'n.c.', 'n.h.', 'n.j', 'n.j.', 'n.j.-based', 'n.m.', 'n.v.', 'n.y.', 'nagano', 'nagymaros', 'najarian', 'name', 'named', 'names', 'nancy', 'napa', 'napolitan', 'narcotics', 'narrow', 'narrowly', 'nasd', 'nasdaq', 'nasty', 'nation', 'national', 'nationale', 'nations', 'nationwide', 'nature', 'navigation', 'navy', 'nbc', 'nbc-owned', 'nbi', 'ncnb', 'neal', 'near', 'near-record', 'nearby', 'nearly', 'nearly-number_token', 'nec', 'necessarily', 'necessary', 'necklace', 'nederlanden', 'need', 'needed', 'needham', 'needing', 'needle-like', 'needs', 'needy', 'negative', 'negatives', 'negotiate', 'negotiated', 'negotiating', 'negotiations', 'negotiator', 'negotiators', 'negus', 'neighborhood', 'neighborhoods', 'neighbors', 'neil', 'neither', 'nekoosa', 'nelms', 'nelson', 'nemeth', 'nervous', 'nervousness', 'nesb', 'nesconset', 'nestor', 'net', 'netherlands', 'nets', 'network', 'networks', 'nev.', 'never', 'nevertheless', 'new', 'new-home', 'newcomer', 'newer', 'newgate', 'newly', 'news', 'newspaper', 'newspapers', 'newsstands', 'newsweek', 'newsweekly', 'newsworthy', 'next', 'nice', 'niches', 'nicholas', 'nickel', 'nicole', 'nielsen', 'night', 'nightmare', 'nih', 'nih-appointed', 'nilson', 'nine', 'nine-member', 'ninth', 'nipponese', 'nissho-iwai', 'nixon', 'nl', 'no', 'no-smoking', 'no.', 'nobel', 'nobody', 'nominal', 'nominated', 'non-biodegradable', 'non-core', 'non-encapsulating', 'non-religious', 'nondurable', 'none', 'nonetheless', 'nonexecutive', 'nonfat', 'nonfinancial', 'nonresidential', 'noodles', 'nor', 'normal', 'normally', 'norman', 'north', 'northampton', 'northeast', 'northern', 'northy', 'norwegian', 'norwest', 'norwick', 'nose', 'not', 'notably', 'note', 'noted', 'notes', 'nothing', 'notice', 'noticing', 'noting', 'notion', 'nov.', 'novel', 'novelist', 'novello', 'november', 'now', 'nowhere', 'ntg', 'nuclear', 'number', 'number_token', 'number_token%-owned', 'number_token-a-share', 'number_token-cent-an-hour', 'number_token-day', 'number_token-hour', 'number_token-lap', 'number_token-lawyer', 'number_token-member', 'number_token-minute', 'number_token-month', 'number_token-point', 'number_token-share', 'number_token-state', 'number_token-stock', 'number_token-week', 'number_token-year', 'number_token-year-old', 'numbered', 'numeral', 'numerous', 'nurtured', 'nutty', \"o'connor\", 'o.', 'obedient', 'objective', 'objectives', 'obligations', 'oblivion', 'observations', 'observed', 'observers', 'observing', 'obsessed', 'obsession', 'obstacles', 'obtain', 'obtained', 'obtaining', 'obvious', 'occupant', 'occupying', 'occur', 'occurred', 'occurrences', 'oct.', 'october', 'octogenarians', 'odd', 'odd-sounding', 'of', 'off', 'off-off', 'offend', 'offender', 'offenders', 'offending', 'offense', 'offer', 'offered', 'offering', 'offers', 'office', 'officer', 'officers', 'offices', 'official', 'officially', 'officials', 'offset', 'often', 'ogilvy', 'ohio', 'oil', 'oilman', 'oils', 'ok', 'old', 'old-house', 'older', 'oldest', 'oliver', 'olsen', 'olympic', 'omitted', 'on', 'on-campus', 'once', 'one', 'one-country', 'one-day', 'one-hour', 'one-month', 'one-third', 'one-time', 'one-upsmanship', 'one-week', 'one-year', 'one-yen', 'ones', 'ongoing', 'only', 'onslaught', 'onto', 'onus', 'open', 'open-end', 'opened', 'opening', 'openly', 'opens', 'operate', 'operated', 'operates', 'operating', 'operational', 'operations', 'operator', 'operators', 'opinion', 'opinions', 'opponents', 'opportunity', 'oppose', 'opposed', 'opposes', 'opposition', 'optical', 'optimism', 'option', 'options', 'opus', 'or', 'orchestra', 'ordeal', 'order', 'ordered', 'ordering', 'orders', 'ore.', 'organization', 'organizations', 'organized', 'original', 'originally', 'orleans', 'orrick', 'orville', 'osaka', 'osborn', 'otc', 'otero', 'other', 'others', 'ounce', 'ounces', 'our', 'out', 'outcry', 'outlawed', 'outlook', 'outpaced', 'output', 'outrage', 'outraged', 'outranks', 'outright', 'outside', 'outsiders', 'outstanding', 'outstrips', 'ovation', 'over', 'over-the-counter', 'overall', 'overhead', 'overlap', 'overpaying', 'overpriced', 'overruns', 'overseas', 'oversee', 'oversight', 'overtime', 'overused', 'owed', 'own', 'owned', 'owner', 'owners', 'owns', 'p.', 'p.m', 'pa.', 'pace', 'pacific', 'pack', 'package', 'packages', 'packaging', 'packed', 'pact', 'page', 'page-one', 'pages', 'paid', 'painewebber', 'painted', 'painting', 'pair', 'palestine', 'palestinian', 'palisades', 'palmer', 'paltry', 'pamela', 'pamplin', 'panama', 'panel', 'panic', 'pap', 'paper', 'papers', 'par', 'parallel', 'parallels', 'pardus', 'parent', 'parents', 'paribas', 'parishes', 'parishioners', 'park', 'parking', 'parkinson', 'parliament', 'parlors', 'part', 'partially', 'participants', 'participation', 'particular', 'particularly', 'particulars', 'parties', 'partisan', 'partisans', 'partly', 'partner', 'partners', 'parts', 'party', 'pass', 'passage', 'passages', 'passbook', 'passed', 'passenger', 'passers-by', 'passing', 'passion', 'passport', 'past', 'pasta', 'pat', 'pate', 'patent', 'patented', 'patents', 'pathlogy', 'patient', 'patricia', 'pattenden', 'pattern', 'patterns', 'paul', 'pay', 'payable', 'paying', 'payment', 'payments', 'payoff', 'payouts', 'payrolls', 'pc', 'pcs', 'peaceful', 'peak', 'peaks', 'peal', 'pealing', 'peals', 'peck', 'peculiar', 'peculiarities', 'pegged', 'pending', 'penetrate', 'penetration', 'peng', 'pennsylvania', 'pennview', 'penny', 'people', 'pep', 'per', 'perceived', 'perceives', 'percentage', 'perception', 'perceptions', 'perch', 'perfection', 'perfectly', 'performance', 'performed', 'performing', 'perhaps', 'perignon', 'period', 'periods', 'peripheral', 'permanent', 'permission', 'permit', 'permitted', 'permitting', 'perpetuate', 'perpetuates', 'perritt', 'persistent', 'person', 'personal', 'personally', 'personnel', 'perspective', 'persuade', 'persuasion', 'pet', 'peter', 'petition', 'petroleum', 'petrus', 'petulant', 'pharmaceutical', 'pharmaceuticals', 'phase', 'phasing', 'phelan', 'phi', 'philadelphia', 'philadelphia-based', 'philippine', 'philippines', 'phillips', 'philosophy', 'phipps', 'phone', 'phony', 'photograph', 'photographic', 'photographs', 'photos', 'phrase', 'physical', 'physicist', 'physics', 'pianist-comedian', 'pick', 'pick-up', 'picked', 'pickens', 'picket', 'picking', 'pickups', 'picture', 'pictures', 'pie', 'piece', 'pieces', 'piero', 'pierre', 'pine', 'pinocchio', 'pioneer', 'piracy', 'pirates', 'pistols', 'pit', 'pitcher', 'pitches', 'pitney', 'pittsburgh', 'place', 'placed', 'places', 'plainclothes', 'plan', 'plane', 'planned', 'planners', 'plans', 'plant', 'plantation', 'planters', 'plants', 'plastic', 'plate', 'platitudes', 'platt', 'play', 'played', 'player', 'players', 'playful', 'playing', 'plays', 'playwright', 'plaza', 'plc', 'pleaded', 'pleased', 'plenty', 'plight', 'plo', 'plot', 'plunge', 'plunged', 'plunging', 'plus', 'pocket', 'poignant', 'point', 'pointed', 'pointing', 'points', 'poland', 'polarized', 'police', 'policies', 'policy', 'polish', 'politely', 'political', 'politicians', 'politics', 'polled', 'polls', 'pollution', 'polyester', 'polyproplene', 'polystyrene', 'polytechnic', 'pont', 'pool', 'poor', 'poore', 'poorly', 'pop', 'popular', 'populated', 'population', 'porter', 'portfolio', 'portfolios', 'portrayal', 'portrayed', 'portugal', 'pose', 'posing', 'position', 'positioned', 'positions', 'positive', 'possessed', 'possessions', 'possibility', 'possible', 'possibly', 'post', 'post-hearing', 'posted', 'posters', 'posting', 'postponed', 'posts', 'potential', 'pounds', 'pour', 'poured', 'powder', 'power', 'powers', 'powwow', 'practical', 'practice', 'practices', 'practicing', 'praised', 'pramual', 'prater', 'pratt', 'prayer', 'pre-approved', 'pre-communist', 'pre-cooked', 'pre-emptive', 'pre-number_token', 'precedent', 'precious', 'precise', 'precisely', 'predecessor', 'predictable', 'predicted', 'predicting', 'prefectural', 'prefecture', 'preferences', 'preferred', 'pregnant', 'prejudice', 'preliminary', 'premier', 'premiere', 'premises', 'premium', 'premiums', 'preparation', 'preparatives', 'prepare', 'prepared', 'prepayment', 'prescient', 'presence', 'presented', 'preset', 'president', 'presidential', 'presidents', 'press', 'pressed', 'pressing', 'pressure', 'pressured', 'pressures', 'prestige', 'prestigious', 'preston', 'presumably', 'pretax', 'pretty', 'prevailing', 'prevent', 'preventing', 'previous', 'previously', 'price', 'priced', 'prices', 'priciest', 'pricing', 'pride', 'primarily', 'primary', 'prime', 'princely', 'princeton', 'principal', 'principals', 'principle', 'print', 'printed', 'prior', 'priority', 'prison', 'privacy', 'private', 'privately', 'privilege', 'privileged', 'prize', 'prize-fighter', 'pro-choice', 'pro-democracy', 'pro-forma', 'probably', 'problem', 'problems', 'procedures', 'proceedings', 'proceeds', 'process', 'processors', 'procurement', 'produce', 'produced', 'producer', 'producers', 'producing', 'product', 'product-design', 'production', 'productions', 'productivity', 'products', 'prof', 'profession', 'professional', 'professionals', 'professor', 'profit', 'profitable', 'profits', 'program', 'program-trading', 'programming', 'programs', 'progress', 'progressive', 'prohibited', 'prohibits', 'project', 'projector', 'projects', 'prolonged', 'prominent', 'prominently', 'promise', 'promising', 'promissory', 'promote', 'promoting', 'promotional', 'promotions', 'prompted', 'promptly', 'proof', 'propelling', 'proper', 'properties', 'property', 'proponent', 'proponents', 'proposal', 'proposals', 'proposed', 'proposing', 'proprietor', 'prosecute', 'prosecuted', 'prosecuting', 'prosecution', 'prosecutor', 'prosecutors', 'prospect', 'prospectively', 'prospects', 'prostitute', 'protect', 'protected', 'protecting', 'protection', 'protections', 'protest', 'protesters', 'protests', 'prototype', 'protracted', 'prove', 'provide', 'provided', 'providence', 'providers', 'provides', 'providing', 'province', 'provision', 'provisions', 'provoke', 'prying', 'ps', 'psychiatrist', 'pta', 'pty.', 'pub', 'public', 'publication', 'publications', 'publicized', 'publicly', 'publish', 'published', 'publisher', 'publishers', 'publishes', 'publishing', 'pull', 'pulled', 'pulling', 'pulls', 'pulp', 'pumping', 'punish', 'punishable', 'punishing', 'punishment', 'punitive', 'purchase', 'purchased', 'purchasers', 'purchases', 'purchasing', 'purely', 'purepac', 'purhasing', 'purpose', 'purrs', 'pursuant', 'pursue', 'pursued', 'push', 'pushes', 'pushing', 'put', 'puts', 'putting', 'qualify', 'quality', 'quantitative', 'quantities', 'quarter', 'quarterly', 'quarters', 'queen', 'queers', 'question', 'questionable', 'questions', 'queuing', 'quick', 'quickly', 'quiet', 'quipped', 'quips', 'quite', 'quitting', 'quotas', 'quoted', 'r', 'r.', 'r.i.', 'r.p.', 'rabia', 'race', 'raced', 'racing', 'radically', 'radio', 'rae', 'rail', 'railcars', 'railroad', 'raise', 'raised', 'raises', 'raising', 'raleigh', 'rally', 'ramirez', 'rampage', 'ran', 'rancor', 'randolph', 'random', 'range', 'ranged', 'ranieri', 'rankin', 'rankings', 'ranks', 'rap', 'rapanelli', 'rape', 'rapid', 'rapidly', 'rapists', 'rapprochement', 'rarefied', 'rarely', 'raring', 'rash', 'raspberry', 'rate', 'rate-sensitive', 'ratepayers', 'rates', 'rather', 'ratings', 'rationed', 'ratners', 'raton', 'raul', 'raw', 'rbc', 're-election', 're-thought', 'reach', 'reached', 'reaches', 'reaction', 'read', 'reader', 'reading', 'ready', 'reagan', 'real', 'real-estate', 'reality', 'realization', 'realize', 'realized', 'really', 'reames', 'reaped', 'rear', 'rear-seat', 'reason', 'reasons', 'reasserts', 'rebellion', 'rebound', 'rebuffed', 'rebuked', 'recalling', 'recalls', 'recede', 'receipts', 'receive', 'received', 'receives', 'receiving', 'recent', 'recently', 'recession', 'recession-inspired', 'recessionary', 'recipient', 'reciting', 'recognition', 'recognize', 'recognizing', 'recommend', 'recommendations', 'recommended', 'record', 'record-keeping', 'recorded', 'records', 'recruit', 'rectified', 'recyclability', 'recycled', 'red', 'red-and-white', 'red-blooded', 'red-carpet', 'red-flag', 'reddington', 'redeem', 'redeemed', 'redeeming', 'redemption', 'redeploy', 'reds', 'reduce', 'reduced', 'reducing', 'reduction', 'reductions', 'reference', 'referendum', 'referrals', 'referred', 'referring', 'refile', 'refitting', 'reflect', 'reflected', 'reflecting', 'reflection', 'reflects', 'refocusing', 'reform', 'reformers', 'reforms', 'refreshing', 'refuge', 'refund', 'refunded', 'refunding', 'refunds', 'refusal', 'refused', 'refuses', 'regard', 'regarded', 'regarding', 'regenerate', 'regimented', 'region', 'regional', 'regions', 'registered', 'registration', 'regret', 'regrettable', 'regular', 'regulate', 'regulated', 'regulating', 'regulation', 'regulators', 'regulatory', 'reins', 'reinstatement', 'reinstating', 'reinvestment', 'reject', 'rejected', 'rekindled', 'related', 'relating', 'relation', 'relations', 'relationship', 'relative', 'relatively', 'release', 'released', 'releases', 'relegated', 'relied', 'relieved', 'remain', 'remainder', 'remained', 'remaining', 'remains', 'remarked', 'remarks', 'remember', 'reminded', 'remodeling', 'remorse', 'removal', 'remove', 'removed', 'rendering', 'renee', 'renew', 'renewal', 'renewed', 'renovated', 'renovation', 'rent-a-car', 'rentals', 'reopen', 'reopened', 'reorganization', 'rep.', 'repaid', 'repair', 'repayment', 'replace', 'replaced', 'replacement', 'replacement-car', 'replacing', 'replete', 'replicate', 'replicated', 'replicating', 'replies', 'report', 'reported', 'reportedly', 'reporting', 'reports', 'represent', 'representative', 'represented', 'representing', 'represents', 'reprove', 'reps', 'republican', 'republicans', 'reputation', 'request', 'requested', 'requests', 'require', 'required', 'requirement', 'requirements', 'requires', 'requiring', 'reruns', 'rescheduled', 'research', 'researcher', 'researchers', 'researching', 'reservations', 'reserve', 'reserves', 'residence', 'residential', 'resignation', 'resigned', 'resilient', 'resist', 'resistance', 'resistant', 'resisting', 'resists', 'resolution', 'resolve', 'resolved', 'resonate', 'resort', 'resources', 'respect', 'respite', 'respond', 'responded', 'responding', 'response', 'responses', 'responsibility', 'rest', 'restaurant', 'restaurants', 'restore', 'restriction', 'restrictions', 'restricts', 'restructure', 'restructured', 'restructuring', 'resubmit', 'result', 'resulting', 'results', 'resume', 'retail', 'retailer', 'retailers', 'retailing', 'retain', 'retained', 'retaining', 'retaliating', 'retaliation', 'retard', 'retardation', 'retentive', 'retin-a', 'retired', 'retires', 'retiring', 'retort', 'retorts', 'return', 'returned', 'returning', 'returns', 'rev.', 'revenue', 'revenue-desperate', 'revenues', 'review', 'reviewed', 'reviewing', 'revising', 'revive', 'revived', 'revolution', 'reward', 'rewarding', 'rewards', 'rexinger', 'rey', 'rhetoric', 'rhone', 'rhythm', 'rhythmically', 'rice', 'rich', 'richard', 'richebourg', 'richmond', 'rick', 'ricken', 'ridgefield', 'rieslings', 'rifles', 'right', 'rights', 'rim', 'ring', 'ringer', 'ringers', 'ringing', 'rings', 'ripen', 'rise', 'risen', 'riserva', 'rises', 'rising', 'risk', 'risks', 'rita', 'ritual', 'rival', 'river', 'road', 'robert', 'robertson', 'robotic', 'robustly', 'rock', 'rockefeller', 'rockford', 'rockwell', 'roederer', 'roger', 'role', 'roll', 'rolled', 'rolling', 'rollover', 'roman', 'romance', 'romanee-conti', 'romanticized', 'ronald', 'roof', 'roof-crush', 'roofs', 'roosevelt', 'rooted', 'rope', 'rope-sight', 'ropes', 'rose', 'rosenblum', 'ross', 'rothschild', 'rotie', 'rouge', 'rough', 'roughhewn', 'roughly', 'roukema', 'round', 'rounds', 'rout', 'route', 'routine', 'row', 'rowe', 'royal', 'royalty', 'rozell', 'rubber', 'rubicam', 'rubinfien', 'rudolph', 'rule', 'ruled', 'rules', 'ruling', 'run', 'run-down', 'rung', 'running', 'runs', 'rural', 'rushed', 'russel', 'russian', 'russo', 'rust', 'rusted', 'rusty', 's&l', 's&p', 's.', 's.p', 's.p.a.', 'sabhavasu', 'sachs', 'sacked', 'sacks', 'sacramento', 'sacramento-based', 'sacrificing', 'safe', 'safe-deposit', 'safety', 'sagging', 'said', 'saitama', 'sake', 'salaries', 'salary', 'salarymen', 'sale', 'sales', 'salmore', 'salomon', 'salon', 'salty', 'same', 'samnick', 'samuel', 'san', 'sanctions', 'sandberg', 'sanderoff', 'sandifer', 'sandra', 'santa', 'sasaki', 'sassy', 'sat', 'satisfaction', 'satisfactory', 'satisfying', 'satrum', 'saturday', 'sauce', 'saudi', 'sauternes', 'sauvignon', 'save', 'savers/investors', 'saving', 'savings', 'savings-and-loan', 'savvier', 'saw', 'say', 'sayers', 'saying', 'says', 'scale', 'scandinavian', 'scarce', 'scared', 'scattered', 'scenario', 'scenes', 'schaefer', 'schedule', 'scheduled', 'scherer', 'scholastic', 'school', 'school-board', 'school-district', 'school-improvement', 'school-research', 'school-sponsored', 'schoolboys', 'schoolchildren', 'schools', 'schoolteacher', 'sci', 'science', 'scientific', 'scientist', 'scientists', 'scoop', 'score', 'scores', 'scoring', 'scotia', 'scott', 'scowcroft', 'scrambled', 'scrambling', 'scrape', 'scrapped', 'screen', 'screens', 'screenwriters', 'screwed', 'scrupulously', 'scrutinizing', 'scrutiny', 'sdi', 'sea', 'seagate', 'seahorse', 'search', 'search-and-seizure', 'season', 'seasonal', 'seasonally', 'seat', 'seats', 'seattle', 'sebastian', 'sec', 'secilia', 'second', 'secondary', 'secret', 'secretary', 'section', 'sections', 'sector', 'sectors', 'secured', 'securities', 'securities-based', 'security', 'security-type', 'seduce', 'see', 'seeing', 'seek', 'seeking', 'seeks', 'seem', 'seemed', 'seems', 'seen', 'segment', 'segmenting', 'segments', 'seized', 'self', 'self-aggrandizing', 'self-esteem', 'self-perpetuating', 'self-regulatory', 'sell', 'sell-offs', 'seller', 'selling', 'sells', 'semesters', 'semiannual', 'semiconductor', 'semiconductors', 'seminar', 'sen.', 'senate', 'senate-house', 'send', 'sending', 'senior', 'seniors', 'sensation', 'sense', 'sensitive', 'sensitivity', 'sent', 'sentencing', 'sentiment', 'seoul', 'separate', 'separately', 'sept.', 'september', 'series', 'serious', 'seriously', 'serve', 'served', 'serves', 'service', 'serviced', 'services', 'servicing', 'serving', 'session', 'set', 'setback', 'sets', 'setting', 'settle', 'settled', 'settlement', 'seven', 'seven-day', 'seven-year', 'seventh', 'several', 'sew', 'sex', 'seymour', 'shaded', 'shadows', 'shake', 'shallow', 'shame', 'shangkun', 'shape', 'shapiro', 'share', 'sharedata', 'shareholder', 'shareholders', 'shares', 'sharp', 'sharper', 'sharply', 'she', 'sheaf', 'shearson', 'sheep', 'sheepskin', 'sheet', 'sheets', 'sheffield', 'shelby', 'sherwin', 'sherwood', 'shipments', 'shipped', 'shipping', 'ships', 'shirt-sleeved', 'shirts', 'shoot', 'shop', 'shops', 'shore', 'shores', 'short', 'short-lived', 'short-term', 'shortage', 'shorter', 'shortly', 'shot', 'should', 'shoulder', 'shovels', 'show', 'showed', 'showing', 'showings', 'shown', 'shows', 'shrinks', 'shrug', 'shrum', 'shugart', 'shut', 'shuxian', 'side', 'side-crash', 'sides', 'sidestep', 'sidewalk', 'siegal', 'sierra', 'sight', 'sights', 'sign', 'signal', 'signaling', 'signals', 'signboards', 'signed', 'signet', 'significance', 'significant', 'significantly', 'signing', 'signs', 'silent', 'silicon', 'similar', 'similarity', 'simmons', 'simon', 'simple', 'simply', 'since', 'singapore', 'single', 'single-digit', 'single-family', 'single-handedly', 'sinister', 'sino-u.s.', 'sir', 'sit', 'sites', 'siti', 'situation', 'situations', 'six', 'six-bottle', 'six-inch', 'six-month', 'six-packs', 'sixth', 'sizable', 'size', 'sketch', 'sketching', 'skidded', 'skilled', 'skills', 'skin', 'skinner', 'skip', 'skipped', 'skirmishes', 'skittishness', 'skokie', 'skyrocketed', 'skyward', 'slack', 'slash', 'slashing', 'slate', 'sleep', 'slew', 'slid', 'slide', 'slides', 'sliding', 'slightly', 'slip', 'slippage', 'slipped', 'sloan', 'slow', 'slowdown', 'slowdowns', 'slower', 'slowing', 'slowly', 'sluggish', 'sluggishness', 'slump', 'smaby', 'small', 'small-company', 'small-time', 'smaller', 'smallest', 'smartly', 'smattering', 'smelting', 'smiles', 'smith', 'smoke', 'smokers', 'smoking', 'smooth', 'snaking', 'snapped', 'snow', 'so', 'so-called', 'soared', 'social', 'social-studies', 'socialist', 'society', 'sociology', 'soft', 'software', 'sogo-shosha', 'soho', 'sol', 'solaia', 'sold', 'soldiers', 'sole', 'solely', 'solemn', 'solicitation', 'solicitous', 'solid', 'solidarity', 'solihull', 'solved', 'solvent', 'some', 'somebody', 'someone', 'somerset', 'something', 'sometimes', 'sometimes-exhausting', 'sometimes-tawdry', 'son', 'sonnett', 'sony', 'soon', 'sooner', 'sophisticated', 'sorry', 'sort', 'sorting', 'sought', 'soul', 'sound', 'sounded', 'sounding', 'sounds', 'soup', 'souper', 'soups', 'source', 'sources', 'south', 'southeast', 'southern', 'soviet', 'soviets', 'space', 'spain', 'spark', 'sparked', 'sparking', 'speak', 'speaking', 'speaks', 'special', 'specialist', 'specialists', 'specialize', 'specializes', 'specializing', 'specialty', 'specific', 'specifics', 'spectacularly', 'speculate', 'speculated', 'speculation', 'speculators', 'speech', 'speed', 'speedway', 'spence', 'spend', 'spenders', 'spending', 'spends', 'spent', 'sphere', 'spiders', 'spielvogel', 'spillane', 'spin-off', 'spinoff', 'spirit', 'spiro', 'spitler', 'split', 'spoke', 'spokesman', 'spokeswoman', 'spokewoman', 'sponsor', 'spoon', 'sport-utility', 'sports', 'spot', 'spotted', 'spouse', 'spread', 'spring', 'springs', 'spur', 'spurns', 'spurred', 'squad', 'square', 'squeezed', 'squier', 'sr.', 'st.', 'stabbed', 'stable', 'stadium', 'staff', 'stag', 'stage', 'stages', 'staggering', 'stairs', 'stake', 'stakes', 'stalemate', 'stalls', 'stamford', 'stance', 'stand', 'standard', 'standardized', 'standards', 'standing', 'standpoint', 'stands', 'stanford', 'stanley', 'star', 'stare', 'stark', 'stars', 'start', 'started', 'starters', 'starting', 'startling', 'starts', 'state', 'state-owned', 'state-supervised', 'stated', 'statement', 'states', 'statewide', 'station', 'stations', 'statistics', 'statue', 'stature', 'status', 'statute', 'stays', 'steadily', 'steady', 'steal', 'stearn', 'steel', 'steelmaker', 'steelworkers', 'steep', 'steeper', 'stem', 'stemming', 'stena', 'step', 'stephanie', 'stephen', 'stephens', 'stepped', 'stepping', 'steps', 'stereotyped', 'sterling', 'steve', 'steven', 'stevens', 'stewart', 'sticker', 'sticker-shock', 'stiff', 'stigma', 'still', 'stirlen', 'stirred', 'stirrings', 'stock', 'stock-index', 'stock-manipulation', 'stock-market', 'stockbroker', 'stockholders', 'stockholm', 'stocks', 'stoked', 'stone', 'stones', 'stood', 'stop', 'stoppage', 'stopped', 'store', 'stored', 'stores', 'stories', 'story', 'straight', 'strains', 'strait', 'strapped', 'strategic', 'strategies', 'street', 'streets', 'strength', 'stress', 'stressed', 'stressing', 'stretching', 'strict', 'strike', 'striking', 'strindberg', 'stringently', 'strings', 'strip', 'stronach', 'strong', 'strong-willed', 'stronger', 'strongest', 'strongly', 'strother', 'structural', 'structurally', 'structures', 'struggled', 'stuart', 'stuck', 'student', 'student-test', 'students', 'studied', 'studies', 'study', 'studying', 'stung', 'stunned', 'stupid', 'style', 'styles', 'sub-markets', 'sub-segments', 'subcommittee', 'subindustry', 'subject', 'subjects', 'subminimum', 'submit', 'subordinate', 'subordinated', 'subscriber', 'subscribers', 'subscription', 'subscriptions', 'subsequent', 'subsidiaries', 'subsidiary', 'subskill', 'subskills', 'substance', 'substantial', 'substantially', 'suburban', 'succeed', 'succeeding', 'succeeds', 'success', 'successful', 'such', 'sudden', 'suddenly', 'sued', 'suffer', 'suffered', 'suffering', 'sufficiency', 'sugarman', 'suggest', 'suggested', 'suggests', 'suing', 'suit', 'sulaiman', 'sullivan', 'sum', 'summary', 'summer', 'summer/winter', 'summoned', 'summons', 'sums', 'sun', 'sunday', 'sundays', 'sunny', 'supercilious', 'supercomputer', 'supercomputers', 'superimposed', 'superintendent', 'superior', 'superiors', 'supermarket', 'superpremiums', 'supplier', 'suppliers', 'supplies', 'supply', 'support', 'supportive', 'supposedly', 'suppression', 'supreme', 'sure', 'surfaced', 'surge', 'surged', 'surgeon', 'surplus', 'surprise', 'surprised', 'surprising', 'surprisingly', 'surrender', 'surrendered', 'survey', 'surveyed', 'survival', 'survive', 'surviving', 'suspect', 'suspects', 'suspend', 'suspended', 'suspension', 'suspensions', 'sustained', 'sutcliffe', 'swap', 'swapped', 'swearingen', 'sweat', 'sweeping', 'sweet', 'sweetened', 'swelling', 'swiftly', 'swim', 'swing', 'switch', 'switched', 'switching', 'symbol', 'symbolic', 'symmetry', 'sympathetic', 'sympathy', 'symphony', 'symptoms', 'synchronized', 'syndication', 'syndrome', 'synergistics', 'system', 'systematic', 'systems', 't-shirts', 't.', 'table', 'tache', 'tactics', 'tad', 'tag', 'tags', 'tailored', 'tailoring', 'tailors', 'taipei', 'taittinger', 'taiwan', 'taizo', 'take', 'taken', 'takeover', 'takes', 'takeshi', 'taking', 'takuma', 'talcott', 'talk', 'talk-show', 'talked', 'talking', 'talks', 'tallies', 'tally', 'tandy', 'tanked', 'taper', 'tapes', 'target', 'targeted', 'targeting', 'targets', 'tariff', 'tarwhine', 'task', 'tassinari', 'taste', 'tasty', 'tatsunori', 'taught', 'tax', 'taxable', 'taxes', 'taxpayer', 'taxpayers', 'tea', 'teach', 'teacher', 'teacher-cadet', 'teachers', 'teaching', 'team', 'teams', 'technical', 'technique', 'techniques', 'technology', 'teddy', 'teenage', 'teetering', 'telecommunications', 'telegraph', 'telephone', 'telephone-information', 'telephones', 'television', 'tell', 'telling', 'tells', 'temple', 'temporarily', 'temptation', 'tempts', 'ten', 'tend', 'tender', 'tenfold', 'tenn.', 'tense', 'tension', 'tenth', 'term', 'terminated', 'terms', 'terrace', 'terrence', 'terrine', 'test', 'test-coaching', 'test-practice', 'test-prep', 'test-preparation', 'tested', 'testify', 'testing', 'tests', 'texan', 'texas', 'textile', 'texture', 'thai', 'thailand', 'than', 'that', 'the', 'theaters', 'their', 'them', 'themselves', 'then', 'theological', 'theory', 'therapies', 'there', 'therefore', 'these', 'they', 'thin', 'thin-lipped', 'thing', 'things', 'think', 'thinking', 'thinks', 'third', 'third-highest', 'third-quarter', 'thirtysomething', 'this', 'thomas', 'those', 'though', 'thought', 'thousands', 'thrall', 'threat', 'threatened', 'threats', 'three', 'three-digit', 'three-lawyer', 'three-quarters', 'three-sevenths', 'three-year', 'thrift', 'thrifts', 'through', 'throughout', 'throws', 'thugs', 'thumbing', 'thursday', 'thus', 'ticket', 'tidily', 'tie-breaking', 'tied', 'ties', 'tigers', 'tight', 'tightened', 'tilt', 'time', 'timely', 'times', 'times-stock', 'timex', 'timing', 'tiny', 'tip', 'tiphook', 'tire', 'tired', 'tissue', 'tissue-transplant', 'tissues', 'titans', 'title', 'to', 'toast', 'tobacco', 'today', 'together', 'toilet', 'tokyo', 'told', 'tom', 'ton', 'tone', 'too', 'took', 'tools', 'top', 'top-level', 'top-yielding', 'topics', 'toronto', 'toronto-based', 'torrent', 'torrington', 'total', 'totaled', 'totaling', 'totally', 'touch', 'touched', 'touchy', 'tough', 'tour', 'tourism', 'touted', 'tow', 'toward', 'tower', 'town', 'townes', 'towns', 'toys', 'traced', 'track', 'tracked', 'tracking', 'tracks', 'trade', 'traded', 'trademark', 'trader', 'traders', 'trades', 'trading', 'trading-company', 'tradition', 'traditional', 'traditionally', 'traffic', 'trailed', 'train', 'trained', 'training', 'training-wage', 'traitor', 'tramp', 'transacting', 'transaction', 'transactions', 'transferring', 'transforming', 'transition', 'transplant', 'transplantation', 'transplants', 'transportation', 'transporting', 'trap', 'travel', 'travelers', 'traveling', 'traverse', 'treasury', 'treat', 'treated', 'treatment', 'treats', 'treble', 'tree', 'trend', 'trends', 'trettien', 'trial', 'trials', 'tricky', 'tried', 'trigger', 'triggered', 'trillion', 'triple', 'tripled', 'triton', 'trockenbeerenauslesen', 'trojan', 'troop', 'trotter', 'trouble', 'troubled', 'troubles', 'troublesome', 'trs-number_token', 'truce', 'trucks', 'trudeau', 'true', 'trust', 'trustco', 'truth', 'truthful', 'try', 'trying', 'tube', 'tubes', 'tuck', 'tuesday', 'tumbled', 'tumultuous', 'tunes', 'turf', 'turkey', 'turmoil', 'turn', 'turnaround', 'turned', 'turning', 'turnover', 'turns', 'tuscany', 'tv', 'twice', 'twin', 'twin-jet', 'twindam', 'twinned', 'two', 'two-letter', 'two-sevenths', 'two-thirds', 'two-week', 'two-year', 'two-year-old', 'type', 'types', 'typically', 'u.k.', 'u.s.', 'u.s.-japan', 'u.s.-japanese', 'u.s.a.', 'u.s.s.r.', 'ultimately', 'ultimatum', 'unabated', 'unattractive', 'unauthorized', 'unavailability', 'unaware', 'unbearably', 'uncanny', 'uncertainty', 'unchanged', 'uncharted', 'unclear', 'uncomfortable', 'uncomplaining', 'under', 'undercut', 'underline', 'underlying', 'underpin', 'underprivileged', 'underscore', 'undersecretary', 'understanding', 'understatement', 'understood', 'undertaking', 'undertone', 'underwriters', 'undiplomatic', 'undisclosed', 'unenticing', 'unethical', 'unfair', 'unfair-trade', 'unfairly', 'unfathomable', 'unfettered', 'unfilled', 'unfortunately', 'unfounded', 'unico', 'unimpeded', 'unintelligible', 'union', 'unions', 'unique', 'unit', 'united', 'units', 'universities', 'university', 'univest', 'unjust', 'unjustified', 'unleashed', 'unless', 'unlike', 'unloaded', 'unmarked', 'unofficial', 'unpleasant', 'unpopularity', 'unproductive', 'unproven', 'unpublished', 'unrealistically', 'unreasonable', 'unrecognizable', 'unrestricted', 'unsettled', 'unsolicited', 'unstinting', 'unsuccessfully', 'unsympathetic', 'until', 'untrained', 'unusual', 'unusually', 'unwary', 'unwashed', 'unwind', 'up', 'upham', 'upheld', 'upon', 'upside', 'upstream', 'uptick', 'upturn', 'upward', 'urge', 'urged', 'urging', 'us', 'use', 'used', 'useful', 'users', 'uses', 'ushered', 'ushering', 'ushers', 'using', 'usual', 'usually', 'utah', 'utilities', 'utility', 'utsumi', 'uzi-model', 'va.', 'vacation', 'vacations', 'vagabond', 'vagrant', 'vague', 'valhi', 'valley', 'valrico', 'valuation', 'valuations', 'value', 'valued', 'values', 'vans', 'vansant', 'vargas', 'variation', 'various', 'vary', 'varying', 'veal', 'vega', 'vegas', 'vehicle', 'vehicles', 'vendors', 'venerable', 'ventilated', 'venture', 'ventures', 'vermont', 'version', 'versions', 'vertically', 'very', 'veselich', 'via', 'viacom', 'vicar', 'vicars', 'vice', 'vichy', 'vicious', 'victim', 'victims', 'victor', 'victory', 'video', 'video-viewing', 'videocassette', 'view', 'viewed', 'viewers', 'viewpoint', 'viewpoints', 'views', 'village', 'vineyard', 'vinken', 'vintage', 'vintages', 'vinyl', 'violate', 'violated', 'violations', 'violence', 'virgin', 'virginia', 'virginians', 'virtually', 'virtues', 'visible', 'vision', 'visit', 'visited', 'visiting', 'visitors', 'vitally', 'vitriolic', 'vitulli', 'voice', 'voices', 'volatile', 'volatility', 'volume', 'voluntarily', 'volunteer', 'vose', 'vote', 'voted', 'voters', 'voting', 'vowed', 'vs.', 'w.', 'w.d.', 'w.n.', 'w.r.', 'wadsworth', 'wafa', 'wafers', 'wage', 'wages', 'waif', 'wait', 'waiting', 'waiving', 'wakayama', 'wake', 'wakui', 'walk', 'walking', 'walkman', 'wall', 'wallowing', 'walt', 'walters', 'want', 'wanted', 'wants', 'war', 'war-damaged', 'war-rationed', 'ward', 'warehousing', 'warn', 'warner', 'warning', 'warnings', 'warns', 'warrant', 'warrants', 'warren', 'warrenton', 'warsaw', 'wary', 'was', 'wash.', 'washington', 'washington-based', 'waste', 'watanabe', 'watch', 'watched', 'watchers', 'watches', 'watching', 'water', 'water-authority', 'waters', 'waterworks', 'watson', 'wave', 'way', 'wayland', 'wayne', 'ways', 'we', 'we-japanese', 'weak', 'weaken', 'weakening', 'weakness', 'wealthy', 'weapon', 'wear', 'wears', 'weatherly', 'weddings', 'wednesday', 'week', 'weekends', 'weeklies', 'weekly', 'weeks', 'weigh', 'weighed', 'weighing', 'weight', 'weird', 'weisfield', 'welcome', 'welcomed', 'well', 'well-connected', 'well-known', 'wells', 'went', 'were', 'west', 'westborough', 'western', 'westminster', 'westport', 'wfrr', 'whas', 'what', 'wheel-loader', 'wheeland', 'wheels', 'whelen', 'when', 'when-issued', 'where', 'whereby', 'wherewithal', 'whether', 'which', 'while', 'whimsical', 'whipsaw', 'whirling', 'whistle', 'white', 'white-collar', 'whiting', 'who', 'whole', 'wholesale', 'whom', 'whose', 'why', 'wickliffe', 'wide', 'widely', 'widespread', 'widow', 'wife', 'wilbur', 'wilcox', 'wild', 'wilder', 'wildly', 'wilfred', 'will', 'william', 'williams', 'willing', 'willingness', 'wilson', 'wilton', 'win', 'window', 'wine', 'wine-buying', 'wine-making', 'wines', 'wings', 'winiarski', 'winning', 'wins', 'winter', 'wisdom', 'wish', 'with', 'withdraw', 'withdrawal', 'withdrawn', 'within', 'without', 'withstand', 'witness', 'witnesses', 'wives', 'wo', 'woman', 'women', 'won', 'wong', 'wood', 'woodcliff', 'woodrow', 'woodward', 'word', 'word-processing', 'words', 'work', 'workbooks', 'worked', 'worker', 'workers', 'working', 'works', 'worksheets', 'world', 'world-wide', 'worms', 'worried', 'worries', 'worry', 'worrying', 'worse', 'worsening', 'worship', 'worst', 'worst-case', 'worth', 'worthy', 'would', 'would-be', 'wound', 'wozniak', 'wpp', 'wrenching', 'wrists', 'writer', 'writers', 'writing', 'written', 'wrong', 'wrongdoing', 'wrote', 'wtd', 'wtvj', 'wu', 'x', 'xiaoping', 'yale', 'yamamoto', 'yang', 'yasser', 'year', 'year-ago', 'year-earlier', 'year-end', 'year-long', 'year-to-year', 'yeargin', 'yearly', 'years', 'yellow', 'yen', 'yen-denominated', 'yen-support', 'yes', 'yesterday', 'yet', 'yield', 'yielded', 'yielding', 'yields', 'york', 'york-based', 'you', 'young', 'younger', 'youngsters', 'your', 'youth', 'youthful', 'youths', 'yquem', 'zaharah', 'zayed', 'zealand', 'zenith', 'zone', 'zoomed', 'zuckerman']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jqa3ACh3s0Cr",
        "outputId": "d8cd0e98-cb39-420a-e747-3bc2a6996573"
      },
      "source": [
        "print(\"Total OOV terms: {0} ({1:.2f}%)\".format(len(tokenizer.oov_terms), 100*float(len(tokenizer.oov_terms)) / len(tokenizer.vocab)))"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total OOV terms: 312 (4.51%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Y2O0g6fr-wL"
      },
      "source": [
        "# Data Conversion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfqkVnQXDPe7"
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "transf_dtype = np.int32\n",
        "\n",
        "categorical_transformer = OneHotEncoder(handle_unknown='ignore', sparse = False, dtype = transf_dtype)\n",
        "\n",
        "lb_make = ColumnTransformer(\n",
        "    transformers = [('cat', categorical_transformer, ['pos']),\n",
        "                   ],\n",
        "                    remainder = 'passthrough'\n",
        "    )\n",
        "\n",
        "ris=lb_make.fit(dataframe_train)\n",
        "dataframe_train_p = pd.DataFrame(ris.transform(dataframe_train))\n",
        "dataframe_val_p = pd.DataFrame(ris.transform(dataframe_val))\n",
        "dataframe_test_p = pd.DataFrame(ris.transform(dataframe_test))\n",
        "\n",
        "dataframe_train_p.rename(columns={38: 'word', 39: 'sentence'},inplace=True)\n",
        "dataframe_val_p.rename(columns={38: 'word', 39: 'sentence'},inplace=True)\n",
        "dataframe_test_p.rename(columns={38: 'word', 39: 'sentence'},inplace=True)\n",
        "\n",
        "lb_make = LabelEncoder()\n",
        "ris=lb_make.fit(dataframe_train['pos'])\n",
        "dataframe_train['label'] =ris.transform(dataframe_train['pos'])\n",
        "dataframe_val['label'] = ris.transform(dataframe_val['pos'])\n",
        "dataframe_test['label'] = ris.transform(dataframe_test['pos'])\n",
        "\n"
      ],
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Md-jV19ZMb_q"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "Y_train = to_categorical(dataframe_train['label'])\n",
        "Y_val = to_categorical(dataframe_val['label'])\n",
        "Y_test = to_categorical(dataframe_test['label'])"
      ],
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qNt_4w24Gw8"
      },
      "source": [
        "def get_sentence_lengths(df):\n",
        "  return list((df.groupby('sentence').count())['word'])\n"
      ],
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EM21f8FPy5u",
        "outputId": "1fab1dbe-54a4-4048-8add-0b3c4c4acb72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(dataframe_train.groupby('sentence')['word'].apply(list))"
      ],
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentence\n",
            "0       [Pierre, Vinken, NUMBER_TOKEN, years, old, wil...\n",
            "1       [Mr., Vinken, is, chairman, of, Elsevier, N.V....\n",
            "2       [The, asbestos, fiber, crocidolite, is, unusua...\n",
            "3       [Lorillard, Inc., the, unit, of, New, York-bas...\n",
            "4       [Although, preliminary, findings, were, report...\n",
            "                              ...                        \n",
            "1859    [It, would, be, a, good, match, Mr., Hahn, and...\n",
            "1860    [The, resulting, company, would, be, the, larg...\n",
            "1861                [But, can, Mr., Hahn, carry, it, off]\n",
            "1862    [In, this, instance, industry, observers, say,...\n",
            "1863    [Says, Kathryn, McAuley, an, analyst, at, Firs...\n",
            "Name: word, Length: 1864, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NH8jnbG4ST5",
        "outputId": "dccd588c-2178-4b78-ad8f-6ddb0dd326ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x = get_sentence_lengths(dataframe_train_p)\n",
        "print(x)"
      ],
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15, 68, 27, 23, 32, 9, 15, 8, 20, 21, 22, 31, 16, 19, 15, 20, 18, 32, 20, 38, 48, 17, 16, 12, 20, 12, 32, 20, 26, 13, 28, 35, 15, 22, 23, 17, 33, 27, 20, 13, 17, 19, 11, 25, 17, 16, 49, 13, 33, 41, 14, 11, 31, 20, 15, 15, 25, 42, 16, 16, 42, 3, 17, 17, 35, 29, 24, 4, 25, 14, 17, 24, 14, 20, 17, 11, 34, 18, 20, 37, 29, 29, 22, 19, 18, 21, 34, 26, 42, 17, 9, 43, 10, 18, 29, 43, 22, 25, 11, 20, 19, 49, 40, 39, 15, 15, 49, 25, 7, 12, 26, 3, 23, 29, 34, 8, 25, 38, 57, 50, 32, 39, 28, 16, 19, 22, 17, 13, 27, 16, 13, 24, 20, 19, 22, 26, 15, 14, 24, 28, 15, 14, 50, 16, 11, 11, 14, 49, 27, 44, 21, 44, 35, 21, 31, 20, 20, 14, 18, 8, 27, 28, 21, 9, 12, 22, 25, 16, 40, 22, 27, 33, 9, 12, 8, 13, 30, 11, 33, 17, 29, 17, 8, 42, 5, 39, 13, 11, 12, 12, 15, 8, 12, 42, 31, 30, 24, 33, 37, 27, 13, 32, 20, 33, 10, 12, 36, 42, 13, 27, 20, 24, 20, 46, 28, 15, 24, 12, 16, 34, 37, 13, 13, 8, 18, 30, 9, 19, 10, 29, 19, 6, 31, 18, 23, 22, 28, 14, 21, 69, 21, 8, 13, 8, 10, 22, 57, 33, 45, 26, 8, 17, 42, 28, 18, 72, 26, 10, 21, 19, 27, 15, 24, 15, 9, 18, 10, 58, 25, 15, 10, 15, 13, 21, 30, 32, 15, 22, 31, 92, 65, 21, 12, 41, 8, 25, 24, 29, 33, 11, 35, 3, 22, 24, 8, 23, 23, 11, 30, 8, 27, 13, 15, 15, 22, 9, 8, 14, 26, 14, 26, 30, 22, 27, 17, 19, 18, 15, 16, 23, 15, 19, 30, 12, 71, 19, 23, 20, 17, 37, 39, 6, 16, 15, 63, 24, 14, 12, 17, 21, 22, 27, 11, 21, 21, 20, 12, 4, 16, 5, 9, 15, 14, 9, 17, 27, 19, 10, 15, 30, 18, 12, 14, 11, 22, 7, 33, 28, 21, 9, 15, 20, 22, 12, 15, 11, 39, 24, 17, 19, 17, 12, 15, 8, 22, 10, 16, 15, 26, 11, 28, 31, 21, 13, 19, 24, 9, 19, 45, 14, 13, 10, 16, 3, 27, 32, 26, 18, 6, 34, 18, 31, 10, 30, 21, 15, 30, 20, 14, 16, 19, 78, 20, 29, 12, 30, 47, 12, 56, 29, 34, 9, 17, 15, 13, 25, 23, 14, 35, 5, 18, 15, 23, 34, 26, 33, 33, 33, 20, 31, 25, 30, 20, 19, 27, 20, 14, 29, 23, 19, 19, 29, 21, 17, 15, 20, 11, 32, 51, 29, 6, 25, 18, 28, 9, 25, 37, 26, 17, 8, 13, 47, 34, 18, 19, 21, 25, 5, 9, 11, 12, 5, 38, 12, 20, 23, 36, 25, 14, 18, 24, 18, 24, 30, 27, 7, 19, 11, 6, 24, 25, 11, 20, 22, 40, 44, 35, 20, 22, 37, 35, 39, 18, 32, 30, 18, 19, 25, 3, 20, 17, 29, 38, 14, 23, 23, 11, 8, 8, 9, 5, 10, 12, 5, 3, 15, 29, 21, 22, 10, 22, 17, 13, 17, 21, 1, 33, 28, 39, 43, 39, 24, 10, 32, 21, 26, 25, 28, 34, 24, 23, 2, 28, 6, 3, 17, 31, 9, 30, 11, 8, 24, 11, 5, 26, 25, 19, 8, 56, 10, 28, 30, 18, 34, 16, 27, 15, 16, 18, 25, 17, 28, 17, 6, 26, 13, 12, 25, 13, 45, 13, 15, 31, 24, 25, 17, 32, 34, 39, 17, 14, 15, 16, 32, 23, 19, 28, 17, 25, 31, 13, 16, 26, 33, 26, 10, 12, 11, 19, 21, 17, 10, 17, 22, 21, 18, 21, 10, 7, 8, 18, 63, 31, 17, 22, 11, 25, 11, 16, 24, 25, 15, 23, 15, 10, 26, 30, 19, 21, 26, 28, 8, 49, 15, 18, 36, 28, 23, 12, 43, 17, 18, 15, 15, 7, 16, 39, 26, 20, 21, 20, 6, 13, 23, 15, 29, 36, 31, 20, 17, 21, 27, 20, 13, 13, 14, 14, 4, 8, 18, 17, 12, 28, 16, 20, 30, 15, 32, 27, 14, 13, 9, 10, 33, 23, 7, 13, 13, 9, 9, 32, 35, 20, 16, 10, 2, 5, 11, 12, 22, 18, 3, 14, 6, 10, 28, 22, 18, 23, 38, 22, 8, 33, 12, 7, 14, 18, 18, 11, 7, 15, 23, 22, 17, 8, 26, 6, 44, 26, 22, 9, 23, 16, 31, 14, 10, 21, 41, 21, 56, 22, 40, 16, 19, 29, 17, 9, 10, 24, 9, 12, 44, 27, 56, 9, 5, 38, 20, 27, 21, 15, 3, 26, 19, 43, 22, 10, 27, 30, 23, 20, 21, 35, 25, 42, 17, 33, 28, 21, 20, 15, 16, 33, 13, 31, 24, 15, 13, 32, 19, 40, 48, 15, 11, 15, 17, 13, 17, 14, 37, 6, 14, 36, 24, 31, 12, 30, 21, 17, 14, 6, 29, 27, 20, 21, 19, 36, 23, 9, 24, 22, 29, 18, 18, 21, 39, 8, 16, 27, 47, 11, 22, 47, 38, 47, 25, 31, 27, 15, 11, 27, 44, 20, 12, 25, 20, 22, 18, 53, 28, 25, 15, 36, 16, 28, 25, 20, 15, 18, 15, 24, 9, 21, 23, 12, 37, 20, 14, 7, 13, 17, 26, 19, 8, 30, 17, 22, 14, 22, 14, 19, 21, 14, 24, 21, 3, 26, 35, 13, 29, 32, 12, 42, 31, 40, 30, 18, 19, 6, 24, 50, 11, 8, 4, 20, 31, 8, 56, 4, 65, 23, 22, 18, 11, 19, 19, 13, 27, 17, 17, 33, 9, 27, 20, 31, 12, 12, 25, 13, 20, 23, 18, 30, 20, 20, 35, 14, 20, 17, 23, 14, 18, 12, 20, 4, 15, 1, 32, 38, 44, 15, 16, 44, 5, 23, 4, 29, 27, 44, 31, 15, 21, 10, 23, 14, 10, 19, 21, 10, 43, 10, 8, 13, 27, 49, 42, 41, 57, 31, 19, 29, 10, 21, 46, 29, 40, 38, 11, 20, 32, 35, 17, 33, 36, 14, 19, 8, 45, 22, 20, 22, 35, 28, 7, 13, 14, 29, 21, 32, 25, 9, 27, 24, 15, 3, 24, 27, 18, 45, 13, 15, 28, 30, 26, 20, 25, 19, 20, 31, 17, 22, 15, 26, 17, 18, 17, 38, 21, 54, 27, 10, 19, 13, 8, 20, 19, 26, 32, 2, 3, 27, 33, 15, 28, 13, 2, 20, 9, 2, 30, 18, 2, 11, 18, 24, 2, 16, 1, 14, 33, 35, 22, 22, 13, 30, 17, 16, 13, 13, 27, 30, 28, 34, 36, 18, 18, 12, 41, 15, 27, 10, 32, 28, 31, 36, 26, 10, 28, 8, 22, 13, 32, 14, 18, 13, 36, 19, 14, 23, 19, 16, 29, 28, 33, 50, 27, 22, 22, 32, 30, 7, 17, 33, 40, 28, 45, 13, 28, 17, 33, 28, 22, 27, 81, 31, 26, 16, 18, 33, 46, 13, 19, 39, 10, 27, 15, 25, 13, 17, 5, 25, 13, 12, 13, 30, 14, 13, 26, 21, 25, 14, 12, 37, 18, 7, 31, 29, 58, 27, 37, 9, 27, 20, 38, 14, 27, 18, 12, 18, 20, 17, 41, 22, 25, 26, 19, 46, 23, 14, 39, 25, 15, 29, 17, 28, 23, 33, 32, 16, 19, 31, 22, 10, 16, 13, 24, 28, 65, 14, 28, 12, 24, 40, 17, 10, 9, 45, 29, 31, 14, 30, 42, 12, 21, 15, 15, 15, 15, 17, 5, 29, 24, 17, 27, 52, 4, 41, 8, 18, 18, 16, 11, 26, 19, 31, 8, 17, 26, 4, 7, 7, 4, 21, 6, 3, 57, 36, 4, 19, 40, 29, 14, 10, 20, 27, 4, 28, 21, 10, 13, 15, 6, 34, 36, 44, 18, 22, 38, 21, 17, 33, 14, 33, 28, 25, 34, 36, 37, 22, 28, 28, 23, 13, 19, 43, 43, 14, 12, 10, 39, 35, 28, 55, 29, 22, 11, 30, 11, 45, 45, 16, 10, 8, 28, 25, 9, 27, 13, 21, 10, 23, 20, 20, 14, 10, 5, 31, 12, 17, 28, 31, 12, 25, 14, 11, 23, 24, 25, 20, 33, 9, 16, 28, 27, 17, 21, 20, 19, 33, 29, 14, 13, 16, 8, 28, 22, 5, 30, 23, 16, 12, 15, 32, 21, 28, 19, 30, 23, 32, 16, 29, 11, 9, 33, 26, 27, 26, 21, 22, 22, 8, 7, 12, 24, 12, 10, 23, 27, 18, 24, 43, 32, 18, 6, 34, 12, 27, 29, 5, 30, 14, 5, 23, 17, 16, 21, 27, 30, 32, 26, 19, 8, 26, 12, 16, 22, 29, 18, 4, 11, 29, 17, 20, 20, 21, 11, 7, 24, 28, 26, 9, 21, 5, 5, 7, 5, 20, 14, 24, 18, 18, 4, 4, 2, 29, 34, 12, 10, 16, 26, 22, 28, 26, 26, 27, 43, 25, 24, 42, 33, 34, 19, 40, 29, 11, 40, 13, 17, 21, 35, 13, 44, 35, 29, 29, 29, 19, 20, 23, 13, 32, 38, 20, 41, 6, 2, 34, 20, 23, 28, 31, 9, 6, 40, 20, 20, 26, 8, 31, 13, 28, 25, 28, 23, 11, 20, 15, 25, 36, 23, 24, 29, 25, 29, 16, 27, 11, 18, 26, 8, 22, 38, 19, 17, 16, 19, 15, 26, 26, 20, 15, 15, 25, 33, 20, 11, 18, 21, 17, 19, 26, 6, 48, 33, 33, 41, 25, 30, 17, 19, 21, 19, 26, 32, 14, 10, 21, 25, 25, 17, 33, 18, 30, 28, 26, 13, 16, 20, 26, 7, 1, 27, 17, 12, 36, 16, 22, 31, 27, 21, 31, 16, 17, 8, 17, 26, 41, 24, 22, 25, 25, 19, 15, 31, 26, 46, 29, 24, 76, 5, 35, 7, 10, 41, 37, 31, 31, 26, 11, 28, 21, 10, 9, 37, 12, 34, 41, 34, 27, 14, 20, 34, 23, 33, 30, 21, 8, 27, 32, 14, 44, 16, 30, 28, 25, 18, 16, 7, 28, 14, 18, 8, 30, 29, 12, 13, 30, 23, 28, 19, 21, 19, 36, 7, 19, 16, 9, 8, 14, 9, 12, 16, 22, 37, 46, 50, 27, 21, 25, 23, 25, 11, 14, 32, 16, 34, 11, 14, 9, 34, 11, 11, 13, 32, 9, 14, 30, 20, 9, 11, 26, 16, 9, 22, 11, 28, 14, 37, 24, 22, 22, 31, 18, 22, 15, 18, 32, 6, 18, 16, 71, 47, 25, 11, 58, 67, 40, 23, 30, 171, 13, 7, 47, 22, 31, 25, 10, 17, 45, 25, 13, 34, 24, 4, 43, 35, 15, 11, 17, 31, 22, 41, 8, 12, 31, 7, 17, 12, 12, 7, 21, 24, 35, 38, 6, 19, 14, 12, 23, 21, 28, 49, 22, 36, 35, 34, 14, 15, 18, 15, 37, 28, 18, 40, 20, 27, 37, 13, 26, 82, 15, 17, 33, 11, 27, 29, 17, 12, 16, 31, 27, 28, 25, 8, 43, 17, 33, 11, 18, 22, 40, 21, 20, 25, 13, 16, 4, 10, 27, 13, 10, 31, 12, 7, 21, 12, 16, 14, 6, 23, 20, 7, 11, 18]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1uKddQlsCRR",
        "outputId": "5b66a6d3-1470-49bd-a4f7-fd109d42c019",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def convert_text(df, tokenizer, is_training=False, max_seq_length=None):\n",
        "    \"\"\"\n",
        "    Converts input text sequences using a given tokenizer\n",
        "\n",
        "    :param texts: either a list or numpy ndarray of strings\n",
        "    :tokenizer: an instantiated tokenizer\n",
        "    :is_training: whether input texts are from the training split or not\n",
        "    :max_seq_length: the max token sequence previously computed with\n",
        "    training texts.\n",
        "\n",
        "    :return\n",
        "        text_ids: a nested list on token indices\n",
        "        max_seq_length: the max token sequence previously computed with\n",
        "        training texts.\n",
        "    \"\"\"\n",
        "\n",
        "    text_ids = tokenizer.convert_tokens_to_ids(df['word'])\n",
        "\n",
        "    # Padding\n",
        "    if is_training:\n",
        "        max_seq_length = int(np.quantile(get_sentence_lengths(df), 0.99))\n",
        "    else:\n",
        "        assert max_seq_length is not None\n",
        "\n",
        "    text_ids = [seq + [0] * (max_seq_length - len(seq)) for seq in text_ids]\n",
        "    text_ids = np.array([seq[:max_seq_length] for seq in text_ids])\n",
        "\n",
        "    if is_training:\n",
        "        return text_ids, max_seq_length\n",
        "    else:\n",
        "        return text_ids\n",
        "\n",
        "# Train\n",
        "x_train, max_seq_length = convert_text(dataframe_train_p, tokenizer, True)\n",
        "print(\"Max token sequence: {}\".format(max_seq_length))\n",
        "\n",
        "print('X train shape: ', x_train.shape)\n",
        "\n",
        "\n",
        "# Val\n",
        "x_val = convert_text(dataframe_val_p, tokenizer, False, max_seq_length)\n",
        "\n",
        "print('X val shape: ', x_val.shape)\n",
        "\n",
        "\n",
        "# Test\n",
        "x_test = convert_text(dataframe_test_p, tokenizer, False, max_seq_length)\n",
        "\n",
        "print('X test shape: ', x_test.shape)"
      ],
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max token sequence: 58\n",
            "X train shape:  (41256, 58)\n",
            "X val shape:  (27406, 58)\n",
            "X test shape:  (13670, 58)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGXRJiA8yIhK"
      },
      "source": [
        "# Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoxzzPIFxMiu"
      },
      "source": [
        "def create_baseline(hidden_units, dense_units, input_shape, activation):\n",
        "    model = Sequential()\n",
        "    model.add(Bidirectional(LSTM(hidden_units, input_shape=input_shape, \n",
        "                        activation=activation[0])))\n",
        "    model.add(Dense(units=dense_units, activation=activation[1]))\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "    return model\n",
        " \n",
        "demo_model = create_baseline(max_seq_length, 38, (max_seq_length,1), activation=['relu', 'relu'])"
      ],
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1mkxPYR9vjz"
      },
      "source": [
        "from keras.layers import Bidirectional\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence"
      ],
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AYGGxdd8HKW",
        "outputId": "2746bda0-f29e-4c5e-f72f-f443d4f3a8d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "embedding_vector_length = 50\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(tokenizer.vocab.keys())+1, embedding_vector_length, input_length=max_seq_length))\n",
        "model.add(Bidirectional(LSTM(max_seq_length, return_sequences=True)))\n",
        "model.add(Dense(38, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "model.fit(x_train, Y_train, validation_data=(x_val, Y_val), epochs=3, batch_size=64)"
      ],
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     (None, 58, 50)            345650    \n",
            "                                                                 \n",
            " bidirectional_5 (Bidirectio  (None, 58, 116)          50576     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 58, 38)            4446      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 400,672\n",
            "Trainable params: 400,672\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-252-4f2a1a4d411c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 810, in train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 1807, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"/usr/local/lib/python3.7/dist-packages/keras/backend.py\", line 5158, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 58, 38) vs (None, 38)).\n"
          ]
        }
      ]
    }
  ]
}